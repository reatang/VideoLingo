"""
# ----------------------------------------------------------------------------
# æ–‡æœ¬åˆ†å‰²æ¨¡å—æ¼”ç¤ºç¨‹åº
# 
# æ¼”ç¤ºé‡æ„åçš„æ–‡æœ¬åˆ†å‰²æ¨¡å—çš„ä½¿ç”¨æ–¹æ³•ï¼š
# 1. NLPåˆ†å‰² - åŸºäºspaCyçš„è¯­æ³•åˆ†å‰²
# 2. è¯­ä¹‰åˆ†å‰² - åŸºäºGPTçš„æ™ºèƒ½åˆ†å‰²
# 3. æ··åˆåˆ†å‰² - å®Œæ•´çš„äºŒé˜¶æ®µåˆ†å‰²æµç¨‹
# 4. ä¸€é”®æ¥å£ - æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼
# ----------------------------------------------------------------------------
"""

import sys
import os
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

base_dir = os.path.join("my_scripts", "output")

def demo_nlp_splitter():
    """æ¼”ç¤ºNLPåˆ†å‰²å™¨"""
    print("=" * 60)
    print("ğŸ“ æ¼”ç¤º1ï¼šNLPåˆ†å‰²å™¨ (åŸºäºspaCy)")
    print("=" * 60)
    
    try:
        from modules.text_splitter import NLPSplitter
        
        # åˆå§‹åŒ–NLPåˆ†å‰²å™¨
        splitter = NLPSplitter(output_dir=base_dir)
        
        # å¤„ç†æ–‡ä»¶
        input_file = paths.get_filepath_by_default("cleaned_chunks.xlsx", base_dir)
        result_file = splitter.split_file(input_file)
        
        print(f"âœ… NLPåˆ†å‰²æ¼”ç¤ºå®Œæˆï¼")
        print(f"ğŸ“ ç»“æœæ–‡ä»¶: {result_file}")
        
        return result_file
        
    except Exception as e:
        print(f"âŒ NLPåˆ†å‰²æ¼”ç¤ºå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return None


def demo_semantic_splitter(input_file: str = None):
    """æ¼”ç¤ºè¯­ä¹‰åˆ†å‰²å™¨"""
    print("\n" + "=" * 60)
    print("ğŸ“ æ¼”ç¤º2ï¼šè¯­ä¹‰åˆ†å‰²å™¨ (åŸºäºGPT)")
    print("=" * 60)
    
    try:
        from modules.text_splitter import SemanticSplitter
        
        # ä½¿ç”¨NLPåˆ†å‰²çš„ç»“æœæˆ–é»˜è®¤æ–‡ä»¶
        if not input_file:
            input_file = paths.get_filepath_by_default("nlp_split_result.txt", base_dir)
        
        if not os.path.exists(input_file):
            print(f"âš ï¸  è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
            print("âš ï¸  è·³è¿‡è¯­ä¹‰åˆ†å‰²æ¼”ç¤º")
            return None
        
        # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿èµ„æºæ¸…ç†
        with SemanticSplitter(
            output_dir="my_scripts/output",
            max_split_length=20
        ) as splitter:
            # å¤„ç†æ–‡ä»¶
            result_file = splitter.split_file(input_file)
        
        print(f"âœ… è¯­ä¹‰åˆ†å‰²æ¼”ç¤ºå®Œæˆï¼")
        print(f"ğŸ“ ç»“æœæ–‡ä»¶: {result_file}")
        
        return result_file
        
    except Exception as e:
        print(f"âŒ è¯­ä¹‰åˆ†å‰²æ¼”ç¤ºå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return None


def demo_hybrid_splitter():
    """æ¼”ç¤ºæ··åˆåˆ†å‰²å™¨"""
    print("\n" + "=" * 60)
    print("ğŸ“ æ¼”ç¤º3ï¼šæ··åˆåˆ†å‰²å™¨ (NLP + GPT)")
    print("=" * 60)
    
    try:
        from modules.text_splitter import HybridSplitter
        
        # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿èµ„æºæ¸…ç†
        with HybridSplitter(
            output_dir=base_dir,
            max_split_length=20,
            keep_intermediate_files=True  # æ¼”ç¤ºæ—¶ä¿ç•™ä¸­é—´æ–‡ä»¶
        ) as splitter:
            # å¤„ç†æ–‡ä»¶
            input_file = paths.get_filepath_by_default("cleaned_chunks.xlsx", base_dir)
            result_file = splitter.split_file(input_file)
        
        print(f"âœ… æ··åˆåˆ†å‰²æ¼”ç¤ºå®Œæˆï¼")
        print(f"ğŸ“ ç»“æœæ–‡ä»¶: {result_file}")
        
        return result_file
        
    except Exception as e:
        print(f"âŒ æ··åˆåˆ†å‰²æ¼”ç¤ºå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return None


def demo_one_line_api():
    """æ¼”ç¤ºä¸€é”®API"""
    print("\n" + "=" * 60)
    print("ğŸ“ æ¼”ç¤º4ï¼šä¸€é”®åˆ†å‰²API (æœ€ç®€å•)")
    print("=" * 60)
    
    try:
        from modules.text_splitter import split_text_complete
        
        # ä¸€é”®å®Œæˆæ‰€æœ‰åˆ†å‰²
        result_file = split_text_complete(
            input_file="cleaned_chunks.xlsx",
            output_dir=base_dir,
            use_semantic_split=True,
            max_split_length=20
        )
        
        print(f"âœ… ä¸€é”®åˆ†å‰²æ¼”ç¤ºå®Œæˆï¼")
        print(f"ğŸ“ ç»“æœæ–‡ä»¶: {result_file}")
        
        return result_file
        
    except Exception as e:
        print(f"âŒ ä¸€é”®åˆ†å‰²æ¼”ç¤ºå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return None


def demo_sentence_splitting():
    """æ¼”ç¤ºå¥å­åˆ—è¡¨åˆ†å‰²"""
    print("\n" + "=" * 60)
    print("ğŸ“ æ¼”ç¤º5ï¼šå¥å­åˆ—è¡¨åˆ†å‰²")
    print("=" * 60)
    
    try:
        from modules.text_splitter import HybridSplitter
        
        # æµ‹è¯•å¥å­åˆ—è¡¨
        test_sentences = [
            "This is a very long sentence that needs to be split into smaller parts for better readability.",
            "è¿™æ˜¯ä¸€ä¸ªå¾ˆé•¿çš„ä¸­æ–‡å¥å­ï¼Œéœ€è¦è¢«åˆ†å‰²æˆæ›´å°çš„éƒ¨åˆ†ä»¥ä¾¿æ›´å¥½çš„é˜…è¯»ä½“éªŒã€‚",
            "Another example of a sentence that is too long and should be divided appropriately.",
        ]
        
        print("ğŸ” åŸå§‹å¥å­:")
        for i, sentence in enumerate(test_sentences):
            print(f"   {i+1}. {sentence}")
        
        # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿èµ„æºæ¸…ç†
        with HybridSplitter(
            output_dir=base_dir,
            max_split_length=15
        ) as splitter:
            # åˆ†å‰²å¥å­
            split_sentences = splitter.split_sentences(test_sentences)
        
        print("\nğŸ“ åˆ†å‰²ç»“æœ:")
        for i, sentence in enumerate(split_sentences):
            print(f"   {i+1}. {sentence}")
        
        print(f"\nâœ… å¥å­åˆ†å‰²æ¼”ç¤ºå®Œæˆ: {len(test_sentences)} -> {len(split_sentences)}")
        
    except Exception as e:
        print(f"âŒ å¥å­åˆ†å‰²æ¼”ç¤ºå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

from modules.common_utils import paths
from modules.config import get_config_manager

def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸ¬ æ–‡æœ¬åˆ†å‰²æ¨¡å—å®Œæ•´æ¼”ç¤º")
    print("é‡æ„åçš„æ¨¡å—æ”¯æŒå¤šç§åˆ†å‰²ç­–ç•¥å’Œçµæ´»çš„APIæ¥å£")

    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    input_file = paths.get_filepath_by_default("cleaned_chunks.xlsx", output_base_dir=base_dir)
    if not os.path.exists(input_file):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        print("è¯·å…ˆè¿è¡Œ AudioTranscriber ç”Ÿæˆ cleaned_chunks.xlsx æ–‡ä»¶")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(base_dir, exist_ok=True)

    # å¯åŠ¨é…ç½®
    config = get_config_manager()
    
    try:
        # é€‰æ‹©æ¼”ç¤ºæ¨¡å¼
        if len(sys.argv) > 1:
            mode = sys.argv[1].lower()
        else:
            mode = "all"
        
        if mode in ["all", "nlp"]:
            nlp_result = demo_nlp_splitter()
        else:
            nlp_result = None
        
        if mode in ["all", "semantic"]:
            demo_semantic_splitter(nlp_result)
        
        if mode in ["all", "hybrid"]:
            demo_hybrid_splitter()
        
        if mode in ["all", "api"]:
            demo_one_line_api()
        
        if mode in ["all", "sentence"]:
            demo_sentence_splitting()
        
        print("\nğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
        print("\nğŸ“š ä½¿ç”¨è¯´æ˜:")
        print("   python my_scripts/4_TextSplitter_demo.py [mode]")
        print("   mode: all(é»˜è®¤) | nlp | semantic | hybrid | api | sentence")
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­æ¼”ç¤º")
    except Exception as e:
        print(f"\nğŸ’¥ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")


if __name__ == "__main__":
    main() 