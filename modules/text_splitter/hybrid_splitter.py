"""
# ----------------------------------------------------------------------------
# æ··åˆæ–‡æœ¬åˆ†å‰²å™¨
# 
# æ•´åˆNLPå’Œè¯­ä¹‰åˆ†å‰²çš„å®Œæ•´æµç¨‹ï¼š
# 1. ç¬¬ä¸€é˜¶æ®µï¼šåŸºäºspaCyçš„NLPåˆ†å‰²ï¼ˆæ ‡ç‚¹ã€è¯­æ³•ç­‰ï¼‰
# 2. ç¬¬äºŒé˜¶æ®µï¼šåŸºäºGPTçš„è¯­ä¹‰åˆ†å‰²ï¼ˆæ™ºèƒ½ç†è§£ã€ä¸Šä¸‹æ–‡ï¼‰
# 3. ç»Ÿä¸€çš„ç»“æœç®¡ç†å’Œè¾“å‡º
# ----------------------------------------------------------------------------
"""

from pathlib import Path
from typing import Optional

from .nlp_splitter import NLPSplitter
from .semantic_splitter import SemanticSplitter
from modules.commons import paths


class HybridSplitter:
    """æ··åˆæ–‡æœ¬åˆ†å‰²å™¨ - ç»“åˆNLPå’Œè¯­ä¹‰åˆ†å‰²"""
    
    def __init__(self, 
                 output_dir: str = "output",
                 max_split_length: int = 20,
                 keep_intermediate_files: bool = False):
        """
        åˆå§‹åŒ–æ··åˆåˆ†å‰²å™¨
        
        Args:
            output_dir: è¾“å‡ºç›®å½•
            max_split_length: è¯­ä¹‰åˆ†å‰²çš„æœ€å¤§é•¿åº¦
            keep_intermediate_files: æ˜¯å¦ä¿ç•™ä¸­é—´æ–‡ä»¶
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        self.max_split_length = max_split_length
        self.keep_intermediate_files = keep_intermediate_files
        
        # åˆå§‹åŒ–åˆ†å‰²å™¨
        self.nlp_splitter = NLPSplitter(
            output_dir=str(self.output_dir),
            enable_all_strategies=True
        )
        
        self.semantic_splitter = SemanticSplitter(
            output_dir=str(self.output_dir),
            max_split_length=max_split_length
        )
        
        print("âœ… æ··åˆåˆ†å‰²å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   è¾“å‡ºç›®å½•: {self.output_dir}")
        print(f"   è¯­ä¹‰åˆ†å‰²æœ€å¤§é•¿åº¦: {max_split_length}")
        print(f"   å¤„ç†æ¨¡å¼: åŒæ­¥å¤„ç†")
    
    def split_file(self, input_file: str, output_file: str = None) -> str:
        """
        å®Œæ•´çš„æ··åˆåˆ†å‰²æµç¨‹
        
        Args:
            input_file: è¾“å…¥Excelæ–‡ä»¶è·¯å¾„ (cleaned_chunks.xlsx)
            output_file: æœ€ç»ˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            æœ€ç»ˆåˆ†å‰²ç»“æœæ–‡ä»¶è·¯å¾„
        """
        print("ğŸš€ å¼€å§‹æ··åˆæ–‡æœ¬åˆ†å‰²æµç¨‹...")
        print("=" * 60)
        
        try:
            # ================================================================
            # ç¬¬ä¸€é˜¶æ®µï¼šNLPåˆ†å‰²
            # ================================================================
            print("\nğŸ“ ç¬¬ä¸€é˜¶æ®µï¼šNLPåˆ†å‰²")
            print("-" * 30)

            input_file = paths.get_filepath_by_default(input_file, output_base_dir=self.output_dir)
            
            nlp_result_file = self.nlp_splitter.split_file(input_file)
            print(f"ğŸ“ NLPåˆ†å‰²ç»“æœ: {nlp_result_file}")
            
            # ================================================================
            # ç¬¬äºŒé˜¶æ®µï¼šè¯­ä¹‰åˆ†å‰²
            # ================================================================
            print("\nğŸ“ ç¬¬äºŒé˜¶æ®µï¼šè¯­ä¹‰åˆ†å‰²")
            print("-" * 30)
            
            # è®¾ç½®æœ€ç»ˆè¾“å‡ºæ–‡ä»¶å
            if not output_file:
                final_output = paths.get_filepath_by_default("split_by_meaning.txt", output_base_dir=self.output_dir)
            else:
                final_output = paths.get_filepath_by_default(output_file, output_base_dir=self.output_dir)
            
            semantic_result_file = self.semantic_splitter.split_file(
                nlp_result_file, 
                str(final_output)
            )
            
            # ================================================================
            # æ¸…ç†ä¸­é—´æ–‡ä»¶
            # ================================================================
            if not self.keep_intermediate_files:
                try:
                    import os
                    os.remove(nlp_result_file)
                    print(f"ğŸ§¹ å·²åˆ é™¤ä¸­é—´æ–‡ä»¶: {nlp_result_file}")
                except Exception as e:
                    print(f"âš ï¸  æ— æ³•åˆ é™¤ä¸­é—´æ–‡ä»¶: {e}")
            
            # ================================================================
            # å®Œæˆæ€»ç»“
            # ================================================================
            print("\nğŸ‰ æ··åˆåˆ†å‰²æµç¨‹å®Œæˆï¼")
            print("=" * 60)
            print(f"ğŸ“ æœ€ç»ˆç»“æœæ–‡ä»¶: {semantic_result_file}")
            
            # ç»Ÿè®¡ä¿¡æ¯
            self._print_final_summary(input_file, semantic_result_file)
            
            return semantic_result_file
            
        except Exception as e:
            print(f"\nğŸ’¥ æ··åˆåˆ†å‰²æµç¨‹å¤±è´¥: {str(e)}")
            raise
    
    def split_sentences(self, sentences: list) -> list:
        """
        å¯¹å¥å­åˆ—è¡¨è¿›è¡Œæ··åˆåˆ†å‰²
        
        Args:
            sentences: è¾“å…¥å¥å­åˆ—è¡¨
            
        Returns:
            åˆ†å‰²åçš„å¥å­åˆ—è¡¨
        """
        print("ğŸš€ å¼€å§‹æ··åˆå¥å­åˆ†å‰²...")
        
        try:
            # ç¬¬ä¸€é˜¶æ®µï¼šNLPåˆ†å‰²
            print("ğŸ“ æ‰§è¡ŒNLPåˆ†å‰²...")
            nlp_sentences = self.nlp_splitter.split_sentences(sentences)
            
            # ç¬¬äºŒé˜¶æ®µï¼šè¯­ä¹‰åˆ†å‰²
            print("ğŸ“ æ‰§è¡Œè¯­ä¹‰åˆ†å‰²...")
            with self.semantic_splitter:
                final_sentences = self.semantic_splitter.split_sentences(nlp_sentences)
            
            print(f"ğŸ‰ æ··åˆå¥å­åˆ†å‰²å®Œæˆ: {len(sentences)} -> {len(final_sentences)}")
            return final_sentences
            
        except Exception as e:
            print(f"âŒ æ··åˆå¥å­åˆ†å‰²å¤±è´¥: {str(e)}")
            # å‘ç”Ÿé”™è¯¯æ—¶è¿”å›åŸå§‹å¥å­
            return sentences
    
    def _print_final_summary(self, input_file: Path, output_file: Path):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡æ‘˜è¦"""
        try:
            # è¯»å–åŸå§‹æ–‡ä»¶ç»Ÿè®¡
            if input_file.suffix == '.xlsx':
                import pandas as pd
                df = pd.read_excel(input_file)
                original_count = len(df)
                original_type = "Excelè¡Œ"
            else:
                with open(input_file, 'r', encoding='utf-8') as f:
                    original_count = sum(1 for line in f if line.strip())
                original_type = "æ–‡æœ¬è¡Œ"
            
            # è¯»å–æœ€ç»ˆç»“æœç»Ÿè®¡
            with open(output_file, 'r', encoding='utf-8') as f:
                final_count = sum(1 for line in f if line.strip())
            
            print(f"ğŸ“Š åˆ†å‰²ç»Ÿè®¡æ‘˜è¦:")
            print(f"   è¾“å…¥: {original_count} {original_type}")
            print(f"   è¾“å‡º: {final_count} åˆ†å‰²å¥å­")
            print(f"   åˆ†å‰²æ¯”ä¾‹: {final_count/original_count:.2f}x")
            
        except Exception as e:
            import traceback
            traceback.print_exc()
            print(f"âš ï¸  æ— æ³•ç”Ÿæˆç»Ÿè®¡æ‘˜è¦: {e}")
    

# ----------------------------------------------------------------------------
# ç‹¬ç«‹è¿è¡Œæµ‹è¯•
# ----------------------------------------------------------------------------
if __name__ == '__main__':
    import sys
    
    # æµ‹è¯•æ··åˆåˆ†å‰²å™¨
    if len(sys.argv) > 1:
        input_file = sys.argv[1]
    else:
        input_file = "log/cleaned_chunks.xlsx"
    
    # è§£æé¢å¤–å‚æ•°
    max_split_length = 20
    
    if len(sys.argv) > 2:
        try:
            max_split_length = int(sys.argv[2])
        except ValueError:
            print("âš ï¸  æ— æ•ˆçš„max_split_lengthå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼20")
    
    try:
        splitter = HybridSplitter(
            max_split_length=max_split_length,
            keep_intermediate_files=True  # æµ‹è¯•æ—¶ä¿ç•™ä¸­é—´æ–‡ä»¶
        )
        
        result_file = splitter.split_file(input_file)
        print(f"\nâœ… æµ‹è¯•å®Œæˆï¼ç»“æœæ–‡ä»¶: {result_file}")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc() 