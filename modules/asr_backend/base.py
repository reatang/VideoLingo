"""
# ----------------------------------------------------------------------------
# ASRå¼•æ“æŠ½è±¡åŸºç±»å’Œæ•°æ®æ¨¡å‹
# 
# å®šä¹‰äº†ç»Ÿä¸€çš„ASRæ¥å£è§„èŒƒï¼Œæ‰€æœ‰å…·ä½“çš„å¼•æ“é€‚é…å™¨éƒ½éœ€è¦å®ç°è¿™äº›æ¥å£
# ä½¿ç”¨æ•°æ®ç±»å®šä¹‰ç»“æ„åŒ–çš„è¿”å›ç»“æœï¼Œç¡®ä¿ç±»å‹å®‰å…¨å’Œä¸€è‡´æ€§
# ----------------------------------------------------------------------------
"""

from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Union, Any
import pandas as pd


@dataclass
class WordTimestamp:
    """è¯çº§åˆ«æ—¶é—´æˆ³ä¿¡æ¯"""
    word: str
    start: float
    end: float
    confidence: Optional[float] = None


@dataclass
class AudioSegment:
    """éŸ³é¢‘æ®µè½ä¿¡æ¯"""
    text: str
    start: float
    end: float
    words: list[WordTimestamp] = field(default_factory=list)
    speaker_id: Optional[str] = None
    language: Optional[str] = None
    confidence: Optional[float] = None


@dataclass
class ASRResult:
    """ASRè½¬å½•ç»“æœçš„æ ‡å‡†åŒ–æ•°æ®ç»“æ„"""
    segments: list[AudioSegment] = field(default_factory=list)
    language: Optional[str] = None
    duration: Optional[float] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼Œä¿æŒä¸åŸæœ‰ä»£ç çš„å…¼å®¹æ€§"""
        return {
            'segments': [
                {
                    'start': seg.start,
                    'end': seg.end,
                    'text': seg.text,
                    'words': [
                        {
                            'word': word.word,
                            'start': word.start,
                            'end': word.end
                        } for word in seg.words
                    ],
                    'speaker_id': seg.speaker_id
                } for seg in self.segments
            ],
            'language': self.language,
            'duration': self.duration
        }
    
    def to_dataframe(self) -> pd.DataFrame:
        """è½¬æ¢ä¸ºDataFrameæ ¼å¼ï¼Œç”¨äºåç»­å¤„ç†"""
        all_words = []
        for segment in self.segments:
            for word in segment.words:
                all_words.append({
                    'text': word.word,
                    'start': word.start,
                    'end': word.end,
                    'speaker_id': segment.speaker_id
                })
        return pd.DataFrame(all_words)
    
    @classmethod
    def from_dict(cls, data: Dict) -> 'ASRResult':
        """ä»å­—å…¸åˆ›å»ºASRResultå®ä¾‹"""
        segments = []
        for seg_data in data.get('segments', []):
            words = []
            for word_data in seg_data.get('words', []):
                words.append(WordTimestamp(
                    word=word_data.get('word', ''),
                    start=word_data.get('start', 0.0),
                    end=word_data.get('end', 0.0)
                ))
            
            segments.append(AudioSegment(
                text=seg_data.get('text', ''),
                start=seg_data.get('start', 0.0),
                end=seg_data.get('end', 0.0),
                words=words,
                speaker_id=seg_data.get('speaker_id')
            ))
        
        return cls(
            segments=segments,
            language=data.get('language'),
            duration=data.get('duration')
        )


class ASREngineBase(ABC):
    """ASRå¼•æ“æŠ½è±¡åŸºç±» - å®šä¹‰ç»Ÿä¸€çš„è½¬å½•æ¥å£"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–ASRå¼•æ“
        
        Args:
            config: å¼•æ“é…ç½®å‚æ•°
        """
        self.config = config or {}
        self._is_initialized = False
    
    @abstractmethod
    def initialize(self) -> None:
        """åˆå§‹åŒ–å¼•æ“èµ„æºï¼ˆæ¨¡å‹åŠ è½½ã€APIè¿æ¥ç­‰ï¼‰"""
        pass
    
    @abstractmethod
    def transcribe(self, 
                  raw_audio_path: str,
                  vocal_audio_path: str,
                  start_time: float = 0.0,
                  end_time: Optional[float] = None) -> ASRResult:
        """
        è½¬å½•éŸ³é¢‘ç‰‡æ®µ
        
        Args:
            raw_audio_path: åŸå§‹éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            vocal_audio_path: äººå£°åˆ†ç¦»åçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            start_time: å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
            end_time: ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰ï¼ŒNoneè¡¨ç¤ºåˆ°éŸ³é¢‘ç»“å°¾
            
        Returns:
            ASRResult: æ ‡å‡†åŒ–çš„è½¬å½•ç»“æœ
        """
        pass
    
    @abstractmethod
    def cleanup(self) -> None:
        """æ¸…ç†å¼•æ“èµ„æº"""
        pass
    
    def is_available(self) -> bool:
        """æ£€æŸ¥å¼•æ“æ˜¯å¦å¯ç”¨"""
        try:
            self.initialize()
            return True
        except Exception:
            return False
    
    def get_supported_languages(self) -> List[str]:
        """è·å–æ”¯æŒçš„è¯­è¨€åˆ—è¡¨"""
        return []
    
    def get_engine_info(self) -> Dict[str, Any]:
        """è·å–å¼•æ“ä¿¡æ¯"""
        return {
            'name': self.__class__.__name__,
            'version': getattr(self, 'version', 'unknown'),
            'supported_languages': self.get_supported_languages(),
            'is_available': self.is_available()
        }


class ASREngineAdapter(ASREngineBase):
    """ASRå¼•æ“é€‚é…å™¨åŸºç±» - æä¾›é€šç”¨çš„é€‚é…å™¨åŠŸèƒ½"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__(config)
        self.engine_name = self.__class__.__name__.replace('Adapter', '')
    
    def _validate_audio_path(self, audio_path: str) -> None:
        """éªŒè¯éŸ³é¢‘æ–‡ä»¶è·¯å¾„"""
        import os
        if not audio_path or not os.path.exists(audio_path):
            raise FileNotFoundError(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
    
    def _adjust_timestamps(self, result: Dict, start_time: float) -> Dict:
        """è°ƒæ•´æ—¶é—´æˆ³åç§»"""
        if start_time > 0:
            for segment in result.get('segments', []):
                segment['start'] += start_time
                segment['end'] += start_time
                for word in segment.get('words', []):
                    if 'start' in word:
                        word['start'] += start_time
                    if 'end' in word:
                        word['end'] += start_time
        return result
    
    def _log_transcription_start(self, start_time: float, end_time: Optional[float]) -> None:
        """è®°å½•è½¬å½•å¼€å§‹æ—¥å¿—"""
        end_str = f"{end_time:.1f}s" if end_time else "ç»“æŸ"
        print(f"ğŸ¤ {self.engine_name}è½¬å½•: {start_time:.1f}s - {end_str}")
    
    def _log_transcription_complete(self, elapsed_time: float) -> None:
        """è®°å½•è½¬å½•å®Œæˆæ—¥å¿—"""
        print(f"âœ… {self.engine_name}è½¬å½•å®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f}ç§’")


# ----------------------------------------------------------------------------
# å…¼å®¹æ€§æ¥å£ - ä¿æŒä¸åŸæœ‰ä»£ç çš„å…¼å®¹æ€§
# ----------------------------------------------------------------------------

def create_legacy_result(asr_result: ASRResult) -> Dict:
    """åˆ›å»ºä¸åŸæœ‰ä»£ç å…¼å®¹çš„ç»“æœæ ¼å¼"""
    return asr_result.to_dict()


def process_legacy_input(raw_audio: str, vocal_audio: str, start: float, end: float) -> Dict[str, Any]:
    """å¤„ç†åŸæœ‰ä»£ç çš„è¾“å…¥å‚æ•°æ ¼å¼"""
    return {
        'raw_audio_path': raw_audio,
        'vocal_audio_path': vocal_audio,
        'start_time': start,
        'end_time': end
    } 