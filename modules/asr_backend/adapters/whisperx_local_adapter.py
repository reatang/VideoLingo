"""
# ----------------------------------------------------------------------------
# WhisperXæœ¬åœ°å¼•æ“é€‚é…å™¨
# 
# å°†æœ¬åœ°WhisperXå¼•æ“é€‚é…åˆ°ç»Ÿä¸€çš„ASRæ¥å£
# æ”¯æŒGPU/CPUè‡ªé€‚åº”ï¼Œæ¨¡å‹è‡ªåŠ¨ä¸‹è½½ï¼Œæ—¶é—´æˆ³å¯¹é½ç­‰åŠŸèƒ½
# ----------------------------------------------------------------------------
"""

import os
import time
import subprocess
import warnings
from typing import Dict, List, Optional, Any

try:
    import torch
    import whisperx
    import librosa
    WHISPERX_AVAILABLE = True
except ImportError:
    WHISPERX_AVAILABLE = False

from ..base import ASREngineAdapter, ASRResult
from ..utils import AudioProcessor

warnings.filterwarnings("ignore")


class WhisperXLocalAdapter(ASREngineAdapter):
    """WhisperXæœ¬åœ°å¼•æ“é€‚é…å™¨"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        super().__init__(config)
        self.version = "1.0.0"
        
        # é…ç½®å‚æ•°
        self.model_dir = config.get('model_dir', '_model_cache_') if config else '_model_cache_'
        self.language = config.get('language', 'auto') if config else 'auto'
        self.model_name = config.get('model_name', 'large-v2') if config else 'large-v2'
        
        # è¿è¡Œæ—¶å˜é‡
        self.device = None
        self.batch_size = None
        self.compute_type = None
        self.model = None
        self.align_model = None
        self.metadata = None
    
    def initialize(self) -> None:
        """åˆå§‹åŒ–WhisperXå¼•æ“"""
        if not WHISPERX_AVAILABLE:
            raise RuntimeError("âŒ WhisperXåº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install whisperx")
        
        if self._is_initialized:
            return
        
        print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–WhisperXæœ¬åœ°å¼•æ“...")
        
        # è®¾ç½®HuggingFaceé•œåƒ
        self._setup_hf_mirror()
        
        # æ£€æµ‹è®¾å¤‡é…ç½®
        self._setup_device_config()
        
        # åŠ è½½ä¸»æ¨¡å‹
        self._load_main_model()
        
        self._is_initialized = True
        print("âœ… WhisperXæœ¬åœ°å¼•æ“åˆå§‹åŒ–å®Œæˆ")
    
    def transcribe(self, 
                  raw_audio_path: str,
                  vocal_audio_path: str,
                  start_time: float = 0.0,
                  end_time: Optional[float] = None) -> ASRResult:
        """è½¬å½•éŸ³é¢‘ç‰‡æ®µ"""
        if not self._is_initialized:
            self.initialize()
        
        self._validate_audio_path(raw_audio_path)
        self._validate_audio_path(vocal_audio_path)
        
        self._log_transcription_start(start_time, end_time)
        start_timer = time.time()
        
        try:
            # åŠ è½½éŸ³é¢‘æ®µ
            raw_audio = self._load_audio_segment(raw_audio_path, start_time, end_time)
            vocal_audio = self._load_audio_segment(vocal_audio_path, start_time, end_time)
            
            # 1. è½¬å½•åŸå§‹éŸ³é¢‘
            print("ğŸ¤ æ­£åœ¨è½¬å½•éŸ³é¢‘...")
            result = self.model.transcribe(
                raw_audio, 
                batch_size=self.batch_size, 
                print_progress=True
            )
            
            # æ¸…ç†GPUå†…å­˜
            if self.device == "cuda":
                del self.model
                torch.cuda.empty_cache()
            
            # æ£€æŸ¥è¯­è¨€
            detected_language = result.get('language', 'unknown')
            if detected_language == 'zh' and self.language != 'zh':
                print("âš ï¸  æ£€æµ‹åˆ°ä¸­æ–‡è¯­éŸ³ï¼Œå»ºè®®è®¾ç½®language='zh'ä»¥è·å¾—æ›´å¥½æ•ˆæœ")
            
            # 2. æ—¶é—´æˆ³å¯¹é½
            print("â° æ­£åœ¨è¿›è¡Œæ—¶é—´æˆ³å¯¹é½...")
            if not self.align_model:
                self._load_align_model(detected_language)
            
            result = whisperx.align(
                result["segments"], 
                self.align_model, 
                self.metadata, 
                vocal_audio, 
                self.device, 
                return_char_alignments=False
            )
            
            # æ¸…ç†GPUå†…å­˜
            if self.device == "cuda":
                torch.cuda.empty_cache()
            
            # 3. è°ƒæ•´æ—¶é—´æˆ³
            result_dict = {'segments': result['segments'], 'language': detected_language}
            result_dict = self._adjust_timestamps(result_dict, start_time)
            
            # 4. è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            asr_result = ASRResult.from_dict(result_dict)
            
            elapsed_time = time.time() - start_timer
            self._log_transcription_complete(elapsed_time)
            
            return asr_result
            
        except Exception as e:
            print(f"âŒ WhisperXè½¬å½•å¤±è´¥: {str(e)}")
            raise
    
    def cleanup(self) -> None:
        """æ¸…ç†å¼•æ“èµ„æº"""
        if hasattr(self, 'model') and self.model:
            del self.model
        if hasattr(self, 'align_model') and self.align_model:
            del self.align_model
        if hasattr(self, 'metadata') and self.metadata:
            del self.metadata
        
        if self.device == "cuda":
            torch.cuda.empty_cache()
        
        self._is_initialized = False
        print("ğŸ§¹ WhisperXå¼•æ“èµ„æºå·²æ¸…ç†")
    
    def get_supported_languages(self) -> List[str]:
        """è·å–æ”¯æŒçš„è¯­è¨€åˆ—è¡¨"""
        return [
            'en', 'zh', 'es', 'fr', 'de', 'it', 'ja', 'ko', 'ru',
            'pt', 'ar', 'hi', 'th', 'vi', 'nl', 'sv', 'da', 'no'
        ]
    
    def is_available(self) -> bool:
        """æ£€æŸ¥å¼•æ“æ˜¯å¦å¯ç”¨"""
        if not WHISPERX_AVAILABLE:
            return False
        try:
            self.initialize()
            return True
        except Exception:
            return False
    
    def _setup_hf_mirror(self) -> None:
        """è®¾ç½®HuggingFaceé•œåƒ"""
        try:
            mirrors = {'Official': 'huggingface.co', 'Mirror': 'hf-mirror.com'}
            fastest_url = f"https://{mirrors['Official']}"
            best_time = float('inf')
            
            print("ğŸ” æ£€æµ‹HuggingFaceé•œåƒ...")
            for name, domain in mirrors.items():
                if os.name == 'nt':
                    cmd = ['ping', '-n', '1', '-w', '3000', domain]
                else:
                    cmd = ['ping', '-c', '1', '-W', '3', domain]
                
                start = time.time()
                result = subprocess.run(cmd, capture_output=True, text=True)
                response_time = time.time() - start
                
                if result.returncode == 0:
                    if response_time < best_time:
                        best_time = response_time
                        fastest_url = f"https://{domain}"
                    print(f"  âœ“ {name}: {response_time:.2f}s")
            
            if best_time == float('inf'):
                print("âš ï¸  æ‰€æœ‰é•œåƒéƒ½æ— æ³•è®¿é—®ï¼Œä½¿ç”¨é»˜è®¤è®¾ç½®")
            else:
                print(f"ğŸš€ é€‰æ‹©é•œåƒ: {fastest_url} ({best_time:.2f}s)")
            
            os.environ['HF_ENDPOINT'] = fastest_url
            
        except Exception as e:
            print(f"âš ï¸  é•œåƒæ£€æµ‹å¤±è´¥: {str(e)}")
    
    def _setup_device_config(self) -> None:
        """è®¾ç½®è®¾å¤‡é…ç½®"""
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        if self.device == "cuda":
            gpu_mem = torch.cuda.get_device_properties(0).total_memory / (1024**3)
            self.batch_size = 16 if gpu_mem > 8 else 2
            self.compute_type = "float16" if torch.cuda.is_bf16_supported() else "int8"
            print(f"ğŸ® GPUå†…å­˜: {gpu_mem:.2f}GB, æ‰¹æ¬¡å¤§å°: {self.batch_size}, è®¡ç®—ç±»å‹: {self.compute_type}")
        else:
            self.batch_size = 1
            self.compute_type = "int8"
            print(f"ğŸ’» ä½¿ç”¨CPUæ¨¡å¼, æ‰¹æ¬¡å¤§å°: {self.batch_size}, è®¡ç®—ç±»å‹: {self.compute_type}")
    
    def _load_main_model(self) -> None:
        """åŠ è½½ä¸»æ¨¡å‹"""
        try:
            # ç¡®å®šæ¨¡å‹åç§°å’Œè·¯å¾„
            if self.language == 'zh':
                model_name = "Huan69/Belle-whisper-large-v3-zh-punct-fasterwhisper"
                local_model = os.path.join(self.model_dir, "Belle-whisper-large-v3-zh-punct-fasterwhisper")
            else:
                model_name = self.model_name
                local_model = os.path.join(self.model_dir, model_name)
            
            # è®¾ç½®æ¨¡å‹é€‰é¡¹
            vad_options = {"vad_onset": 0.500, "vad_offset": 0.363}
            asr_options = {"temperatures": [0], "initial_prompt": ""}
            whisper_language = None if 'auto' in self.language else self.language
            
            print("âš ï¸  å¯å¿½ç•¥torchç‰ˆæœ¬è­¦å‘Šä¿¡æ¯")
            
            # åŠ è½½æ¨¡å‹
            self.model = whisperx.load_model(
                model_name, 
                self.device, 
                compute_type=self.compute_type, 
                language=whisper_language, 
                vad_options=vad_options, 
                asr_options=asr_options, 
                download_root=self.model_dir
            )
            
            print("âœ… ä¸»æ¨¡å‹åŠ è½½å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ åŠ è½½ä¸»æ¨¡å‹å¤±è´¥: {str(e)}")
            raise
    
    def _load_align_model(self, language: str) -> None:
        """åŠ è½½å¯¹é½æ¨¡å‹"""
        try:
            print(f"ğŸ“¥ åŠ è½½{language}è¯­è¨€å¯¹é½æ¨¡å‹...")
            self.align_model, self.metadata = whisperx.load_align_model(
                language_code=language, 
                device=self.device
            )
            print("âœ… å¯¹é½æ¨¡å‹åŠ è½½å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ åŠ è½½å¯¹é½æ¨¡å‹å¤±è´¥: {str(e)}")
            raise
    
    def _load_audio_segment(self, 
                          audio_file: str, 
                          start_time: float, 
                          end_time: Optional[float]) -> 'numpy.ndarray':
        """åŠ è½½éŸ³é¢‘æ®µ"""
        try:
            duration = end_time - start_time if end_time else None
            audio, _ = librosa.load(
                audio_file, 
                sr=16000, 
                offset=start_time, 
                duration=duration, 
                mono=True
            )
            return audio
            
        except Exception as e:
            print(f"âŒ åŠ è½½éŸ³é¢‘æ®µå¤±è´¥: {str(e)}")
            raise 