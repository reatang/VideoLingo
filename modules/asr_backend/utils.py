"""
# ----------------------------------------------------------------------------
# éŸ³é¢‘å¤„ç†å·¥å…·ç±»
# 
# æä¾›éŸ³é¢‘ç›¸å…³çš„é€šç”¨åŠŸèƒ½ï¼š
# 1. éŸ³é¢‘æ ¼å¼è½¬æ¢å’Œå¤„ç†
# 2. éŸ³é‡æ ‡å‡†åŒ–
# 3. éŸ³é¢‘æ—¶é•¿è·å–
# 4. éŸ³é¢‘åˆ†æ®µå¤„ç†
# 5. è½¬å½•ç»“æœå¤„ç†
# ----------------------------------------------------------------------------
"""

import os
import subprocess
import pandas as pd
from typing import Dict, List, Tuple, Optional
from pydub import AudioSegment
from pydub.silence import detect_silence
from pydub.utils import mediainfo
from pathlib import Path
from .base import ASRResult


class AudioProcessor:
    """éŸ³é¢‘å¤„ç†å™¨ç±» - å°è£…éŸ³é¢‘ç›¸å…³çš„é€šç”¨æ“ä½œ"""

    @staticmethod
    def normalize_audio_volume(audio_path: str, 
                             output_path: str, 
                             target_db: Optional[float] = -20.0,
                             format: str = "wav") -> str:
        """
        æ ‡å‡†åŒ–éŸ³é¢‘éŸ³é‡
        
        Args:
            audio_path: è¾“å…¥éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„
            target_db: ç›®æ ‡dBå€¼ï¼ŒNoneåˆ™ä½¿ç”¨é»˜è®¤å€¼
            format: è¾“å‡ºæ ¼å¼
            
        Returns:
            æ ‡å‡†åŒ–åçš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        """
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
        
        try:
            audio = AudioSegment.from_file(audio_path)
            original_db = audio.dBFS
            
            # è®¡ç®—éœ€è¦è°ƒæ•´çš„åˆ†è´æ•°
            change_in_dBFS = target_db - original_db
            normalized_audio = audio.apply_gain(change_in_dBFS)
            
            # å¯¼å‡ºæ ‡å‡†åŒ–åçš„éŸ³é¢‘
            normalized_audio.export(output_path, format=format)
            
            print(f"âœ… éŸ³é¢‘éŸ³é‡æ ‡å‡†åŒ–å®Œæˆ: {original_db:.1f}dB -> {target_db:.1f}dB")
            return output_path
            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘æ ‡å‡†åŒ–å¤±è´¥: {str(e)}")
            raise
    
    @staticmethod
    def convert_video_to_audio(video_file: str, 
                             output_path: str,
                             audio_format: str = "mp3",
                             sample_rate: int = 16000,
                             channels: int = 1,
                             bitrate: str = "32k") -> str:
        """
        å°†è§†é¢‘æ–‡ä»¶è½¬æ¢ä¸ºéŸ³é¢‘æ–‡ä»¶
        
        Args:
            video_file: è§†é¢‘æ–‡ä»¶è·¯å¾„
            output_path: è¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„
            audio_format: éŸ³é¢‘æ ¼å¼
            sample_rate: é‡‡æ ·ç‡
            channels: å£°é“æ•°
            bitrate: æ¯”ç‰¹ç‡
            
        Returns:
            éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        """
        if not os.path.exists(video_file):
            raise FileNotFoundError(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_file}")
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        
        if os.path.exists(output_path):
            print(f"âœ… éŸ³é¢‘æ–‡ä»¶å·²å­˜åœ¨: {output_path}")
            return output_path
        
        print(f"ğŸ¬â¡ï¸ğŸµ æ­£åœ¨ä½¿ç”¨FFmpegè½¬æ¢ä¸ºé«˜è´¨é‡éŸ³é¢‘...")
        
        try:
            cmd = [
                'ffmpeg', '-y', '-i', video_file, '-vn',
                '-c:a', 'libmp3lame' if audio_format == 'mp3' else 'pcm_s16le',
                '-b:a', bitrate,
                '-ar', str(sample_rate),
                '-ac', str(channels),
                '-metadata', 'encoding=UTF-8', 
                output_path
            ]
            
            # ä¿®å¤Windowsç¼–ç é—®é¢˜ï¼šä½¿ç”¨bytesæ¨¡å¼å¹¶æ‰‹åŠ¨å¤„ç†ç¼–ç 
            result = subprocess.run(
                cmd, 
                check=True, 
                capture_output=True, 
                text=False  # ä½¿ç”¨bytesæ¨¡å¼é¿å…ç¼–ç é—®é¢˜
            )
            
            # æ‰‹åŠ¨è§£ç è¾“å‡ºï¼Œä½¿ç”¨é”™è¯¯å¤„ç†ç­–ç•¥
            try:
                stdout_text = result.stdout.decode('utf-8', errors='ignore')
                stderr_text = result.stderr.decode('utf-8', errors='ignore')
            except:
                # å¦‚æœUTF-8å¤±è´¥ï¼Œå°è¯•ç³»ç»Ÿé»˜è®¤ç¼–ç 
                import locale
                try:
                    encoding = locale.getpreferredencoding()
                    stdout_text = result.stdout.decode(encoding, errors='ignore')
                    stderr_text = result.stderr.decode(encoding, errors='ignore')
                except:
                    stdout_text = str(result.stdout)
                    stderr_text = str(result.stderr)
            
            print(f"âœ… è§†é¢‘è½¬éŸ³é¢‘å®Œæˆ: {video_file} -> {output_path}")
            return output_path
            
        except subprocess.CalledProcessError as e:
            # å¤„ç†é”™è¯¯ä¿¡æ¯çš„ç¼–ç é—®é¢˜
            try:
                if hasattr(e, 'stderr') and e.stderr:
                    if isinstance(e.stderr, bytes):
                        error_msg = e.stderr.decode('utf-8', errors='ignore')
                    else:
                        error_msg = str(e.stderr)
                else:
                    error_msg = "FFmpegæ‰§è¡Œå¤±è´¥"
            except:
                error_msg = "FFmpegæ‰§è¡Œå¤±è´¥ï¼ˆæ— æ³•è§£æé”™è¯¯ä¿¡æ¯ï¼‰"
            
            print(f"âŒ è§†é¢‘è½¬éŸ³é¢‘å¤±è´¥: {error_msg}")
            raise RuntimeError(f"FFmpegè½¬æ¢å¤±è´¥: {error_msg}")
        except FileNotFoundError:
            raise RuntimeError("âŒ æœªæ‰¾åˆ°FFmpeg, è¯·ç¡®ä¿å·²å®‰è£…å¹¶æ·»åŠ åˆ°PATHç¯å¢ƒå˜é‡")
        except Exception as e:
            print(f"âŒ è§†é¢‘è½¬éŸ³é¢‘å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}")
            raise
    
    @staticmethod
    def get_audio_duration(audio_file: str) -> float:
        """
        è·å–éŸ³é¢‘æ–‡ä»¶æ—¶é•¿
        
        Args:
            audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        """
        if not os.path.exists(audio_file):
            raise FileNotFoundError(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
        
        try:
            cmd = ['ffmpeg', '-i', audio_file]
            process = subprocess.Popen(
                cmd, 
                stdout=subprocess.PIPE, 
                stderr=subprocess.PIPE
            )
            stdout_bytes, stderr_bytes = process.communicate()
            
            # ä¿®å¤Windowsç¼–ç é—®é¢˜ï¼šæ‰‹åŠ¨è§£ç è¾“å‡º
            try:
                output = stderr_bytes.decode('utf-8', errors='ignore')
            except:
                # å¦‚æœUTF-8å¤±è´¥ï¼Œå°è¯•ç³»ç»Ÿé»˜è®¤ç¼–ç 
                import locale
                try:
                    encoding = locale.getpreferredencoding()
                    output = stderr_bytes.decode(encoding, errors='ignore')
                except:
                    output = str(stderr_bytes)
            
            # è§£ææ—¶é•¿ä¿¡æ¯
            duration_lines = [line for line in output.split('\n') if 'Duration' in line]
            if not duration_lines:
                # å¤‡ç”¨æ–¹æ³•ï¼šä½¿ç”¨pydub
                audio = AudioSegment.from_file(audio_file)
                return len(audio) / 1000.0
            
            duration_str = duration_lines[0].split('Duration: ')[1].split(',')[0]
            duration_parts = duration_str.split(':')
            
            duration = (
                float(duration_parts[0]) * 3600 + 
                float(duration_parts[1]) * 60 + 
                float(duration_parts[2])
            )
            
            return duration
            
        except Exception as e:
            print(f"âš ï¸  è·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {str(e)}")
            return 0.0
    
    @staticmethod
    def split_audio_by_silence(audio_file: str,
                             target_length: float = 30*60,
                             silence_window: float = 60,
                             safe_margin: float = 0.5) -> List[Tuple[float, float]]:
        """
        åŸºäºé™é»˜æ£€æµ‹æ™ºèƒ½åˆ†å‰²éŸ³é¢‘
        
        Args:
            audio_file: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            target_length: ç›®æ ‡åˆ†æ®µé•¿åº¦ï¼ˆç§’ï¼‰
            silence_window: é™é»˜æ£€æµ‹çª—å£ï¼ˆç§’ï¼‰
            
        Returns:
            åˆ†æ®µåˆ—è¡¨, æ¯ä¸ªå…ƒç´ ä¸º(å¼€å§‹æ—¶é—´, ç»“æŸæ—¶é—´)çš„å…ƒç»„
        """
        print(f"ğŸ™ï¸ å¼€å§‹éŸ³é¢‘æ™ºèƒ½åˆ†æ®µ: {audio_file}")
        
        if not os.path.exists(audio_file):
            raise FileNotFoundError(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
        
        try:
            audio = AudioSegment.from_file(audio_file)
            duration = float(mediainfo(audio_file)["duration"])
            
            print(f"ğŸ“ éŸ³é¢‘æ€»æ—¶é•¿: {duration:.1f}ç§’")
            
            # å¦‚æœéŸ³é¢‘é•¿åº¦åœ¨å…è®¸èŒƒå›´å†…ï¼Œä¸éœ€è¦åˆ†å‰²
            if duration <= target_length + silence_window:
                print("ğŸ“ éŸ³é¢‘é•¿åº¦é€‚ä¸­ï¼Œæ— éœ€åˆ†å‰²")
                return [(0, duration)]
            
            segments = []
            pos = 0.0
            
            while pos < duration:
                # å¦‚æœå‰©ä½™æ—¶é•¿ä¸è¶…è¿‡ç›®æ ‡é•¿åº¦ï¼Œç›´æ¥ä½œä¸ºæœ€åä¸€æ®µ
                if duration - pos <= target_length:
                    segments.append((pos, duration))
                    break
                
                # è®¡ç®—åˆ†å‰²ç‚¹æœç´¢åŒºé—´
                threshold = pos + target_length
                window_start = int((threshold - silence_window) * 1000)
                window_end = int((threshold + silence_window) * 1000)
                
                # ç¡®ä¿çª—å£ä¸è¶…å‡ºéŸ³é¢‘èŒƒå›´
                window_end = min(window_end, len(audio))
                
                if window_start >= window_end:
                    # çª—å£æ— æ•ˆï¼Œä½¿ç”¨é˜ˆå€¼ç‚¹åˆ†å‰²
                    segments.append((pos, threshold))
                    pos = threshold
                    continue
                
                # åœ¨çª—å£å†…æ£€æµ‹é™é»˜åŒºåŸŸ
                silence_regions = detect_silence(
                    audio[window_start:window_end],
                    min_silence_len=int(safe_margin * 1000),
                    silence_thresh=-30
                )
                
                # å°†é™é»˜åŒºåŸŸæ—¶é—´è½¬æ¢ä¸ºç»å¯¹æ—¶é—´
                silence_regions = [
                    (s/1000 + (threshold - silence_window), 
                     e/1000 + (threshold - silence_window))
                    for s, e in silence_regions
                ]
                
                # ç­›é€‰æœ‰æ•ˆçš„é™é»˜åŒºåŸŸ
                valid_regions = [
                    (start, end) for start, end in silence_regions 
                    if (end - start) >= (safe_margin * 2) and 
                       threshold <= start + safe_margin <= threshold + silence_window
                ]
                
                if valid_regions:
                    # ä½¿ç”¨ç¬¬ä¸€ä¸ªæœ‰æ•ˆé™é»˜åŒºåŸŸ
                    start, end = valid_regions[0]
                    split_at = start + safe_margin
                    print(f"ğŸ¯ åœ¨é™é»˜åŒºåŸŸåˆ†å‰²: {split_at:.1f}ç§’")
                else:
                    # æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„é™é»˜åŒºåŸŸï¼Œä½¿ç”¨é˜ˆå€¼ç‚¹
                    split_at = threshold
                    print(f"âš ï¸  æœªæ‰¾åˆ°é™é»˜åŒºåŸŸï¼Œåœ¨é˜ˆå€¼ç‚¹åˆ†å‰²: {split_at:.1f}ç§’")
                
                segments.append((pos, split_at))
                pos = split_at
            
            print(f"âœ… éŸ³é¢‘åˆ†å‰²å®Œæˆï¼Œå…±{len(segments)}ä¸ªç‰‡æ®µ")
            
            # æ‰“å°åˆ†æ®µä¿¡æ¯
            for i, (start, end) in enumerate(segments):
                print(f"  ğŸ“ ç‰‡æ®µ{i+1}: {start:.1f}s - {end:.1f}s ({end-start:.1f}s)")
            
            return segments
            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘åˆ†å‰²å¤±è´¥: {str(e)}")
            raise

    @staticmethod
    def process_transcription_result(result: ASRResult) -> pd.DataFrame:
        """
        å¤„ç†è½¬å½•ç»“æœ, è½¬æ¢ä¸ºæ ‡å‡†DataFrameæ ¼å¼
        
        Args:
            result: ASRå¼•æ“è¿”å›çš„è½¬å½•ç»“æœ
            
        Returns:
            å¤„ç†åçš„DataFrame
        """
        print("ğŸ“Š æ­£åœ¨å¤„ç†è½¬å½•ç»“æœ...")
        
        # ä½¿ç”¨ASRResultå†…ç½®çš„è½¬æ¢æ–¹æ³•
        df = result.to_dataframe()
        
        if df.empty:
            raise ValueError("âŒ æœªèƒ½æå–åˆ°æœ‰æ•ˆçš„è½¬å½•ç»“æœ")
        
        # åŸºæœ¬æ•°æ®æ¸…ç†
        initial_rows = len(df)
        
        # ç§»é™¤ç©ºæ–‡æœ¬è¡Œ
        df = df[df['text'].str.len() > 0]
        removed_empty = initial_rows - len(df)
        if removed_empty > 0:
            print(f"ğŸ§¹ ç§»é™¤äº†{removed_empty}è¡Œç©ºæ–‡æœ¬")
        
        # æ£€æŸ¥å¹¶ç§»é™¤è¿‡é•¿è¯æ±‡
        long_words = df[df['text'].str.len() > 30]
        if not long_words.empty:
            print(f"âš ï¸  æ£€æµ‹åˆ°{len(long_words)}ä¸ªè¿‡é•¿è¯æ±‡ï¼Œå·²ç§»é™¤")
            df = df[df['text'].str.len() <= 30]
        
        # æ¸…ç†ç‰¹æ®Šå­—ç¬¦
        df['text'] = df['text'].replace({'Â»': '', 'Â«': ''}, regex=True)
        
        print(f"âœ… è½¬å½•ç»“æœå¤„ç†å®Œæˆï¼Œå…±{len(df)}ä¸ªè¯æ±‡")
        
        return df
    

# ----------------------------------------------------------------------------
# é…ç½®è¯»å–å·¥å…·
# ----------------------------------------------------------------------------
from ..configs import ConfigManager, get_global_config
from .base import ASRConfig

def get_asr_config(config: Optional[ConfigManager] = None) -> ASRConfig:
    """è·å–ASRé…ç½®"""

    if config is None:
        config = get_global_config()

    return ASRConfig(
        language=config.load_key('whisper.language', 'auto'),
        model=config.load_key('whisper.model', 'large-v3'),
        detected_language=config.load_key('whisper.detected_language', 'auto'),
        runtime=config.load_key('whisper.runtime', 'local'),
        whisperX_302_api_key=config.load_key('whisper.whisperX_302_api_key', ''),
        elevenlabs_api_key=config.load_key('whisper.elevenlabs_api_key', ''),
        model_dir=config.load_key('model_dir', '_model_cache_'),
        demucs=config.load_key('demucs', True)
    )

# ----------------------------------------------------------------------------
# å…¼å®¹æ€§å‡½æ•° - ä¿æŒä¸åŸæœ‰ä»£ç çš„å…¼å®¹æ€§
# ----------------------------------------------------------------------------

def normalize_audio_volume(audio_path: str, 
                         output_path: str, 
                         target_db: float = -20.0, 
                         format: str = "wav") -> str:
    """å…¼å®¹æ€§å‡½æ•° - éŸ³é¢‘éŸ³é‡æ ‡å‡†åŒ–"""
    return AudioProcessor.normalize_audio_volume(audio_path, output_path, target_db, format)


def convert_video_to_audio(video_file: str, output_path: str) -> str:
    """å…¼å®¹æ€§å‡½æ•° - è§†é¢‘è½¬éŸ³é¢‘"""
    return AudioProcessor.convert_video_to_audio(video_file, output_path)


def get_audio_duration(audio_file: str) -> float:
    """å…¼å®¹æ€§å‡½æ•° - è·å–éŸ³é¢‘æ—¶é•¿"""
    return AudioProcessor.get_audio_duration(audio_file)


def split_audio(audio_file: str, 
               target_len: float = 30*60, 
               win: float = 60) -> List[Tuple[float, float]]:
    """å…¼å®¹æ€§å‡½æ•° - éŸ³é¢‘åˆ†æ®µ"""
    return AudioProcessor.split_audio_by_silence(audio_file, target_len, win)


def process_transcription(result: Dict) -> pd.DataFrame:
    """å…¼å®¹æ€§å‡½æ•° - å¤„ç†è½¬å½•ç»“æœ"""
    return AudioProcessor.process_transcription_result(result)