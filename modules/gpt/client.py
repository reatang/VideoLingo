"""
# ----------------------------------------------------------------------------
# GPTå®¢æˆ·ç«¯æ ¸å¿ƒå®ç°
# 
# åŸºäºåŸæœ‰ask_gpté€»è¾‘é‡æ„çš„ç°ä»£åŒ–GPTå®¢æˆ·ç«¯
# æ”¯æŒå¤šç§APIæä¾›å•†ã€é…ç½®ç®¡ç†ã€ç¼“å­˜ç­‰åŠŸèƒ½
# ----------------------------------------------------------------------------
"""

import os
import json
import json_repair
from typing import Optional, Dict, Any
from openai import OpenAI

from .models import GPTRequest, GPTResponse
from .cache import GPTCache
from .exceptions import GPTError, GPTTimeoutError, GPTValidationError


class GPTClient:
    """ç°ä»£åŒ–çš„GPTå®¢æˆ·ç«¯ç±»"""
    
    def __init__(self, 
                 api_key: Optional[str] = None,
                 base_url: Optional[str] = None,
                 model: Optional[str] = None,
                 llm_support_json: bool = False,
                 cache_dir: str = 'output/gpt_log',
                 config_manager=None):
        """
        åˆå§‹åŒ–GPTå®¢æˆ·ç«¯
        
        Args:
            api_key: APIå¯†é’¥
            base_url: APIåŸºç¡€URL
            model: æ¨¡å‹åç§°
            llm_support_json: æ˜¯å¦æ”¯æŒJSONæ¨¡å¼
            cache_dir: ç¼“å­˜ç›®å½•
            config_manager: é…ç½®ç®¡ç†å™¨
        """
        self._config_manager = config_manager
        self._init_from_config(api_key, base_url, model, llm_support_json)
        
        # åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
        self._client = OpenAI(
            api_key=self.api_key,
            base_url=self._normalize_base_url(self.base_url)
        )
        
        # åˆå§‹åŒ–ç¼“å­˜
        self.cache = GPTCache(cache_dir)
        
        print(f"âœ… GPTå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")
        print(f"   æ¨¡å‹: {self.model}")
        print(f"   åŸºç¡€URL: {self.base_url}")
        print(f"   JSONæ”¯æŒ: {self.llm_support_json}")
    
    def _init_from_config(self, api_key, base_url, model, llm_support_json):
        """ä»é…ç½®åˆå§‹åŒ–å‚æ•°"""
        if self._config_manager:
            try:
                api_config = self._config_manager.get_api_config()
                self.api_key = api_key or api_config.get('key', '')
                self.base_url = base_url or api_config.get('base_url', 'https://api.siliconflow.cn')
                self.model = model or api_config.get('model', 'deepseek-ai/DeepSeek-V3')
                self.llm_support_json = llm_support_json if llm_support_json is not None else api_config.get('llm_support_json', False)
            except Exception:
                # ä½¿ç”¨é»˜è®¤å€¼
                self.api_key = api_key or ''
                self.base_url = base_url or 'https://api.siliconflow.cn'
                self.model = model or 'deepseek-ai/DeepSeek-V3'
                self.llm_support_json = llm_support_json or False
        else:
            # å°è¯•ä»ç¯å¢ƒå˜é‡æˆ–ä½¿ç”¨é»˜è®¤å€¼
            self.api_key = api_key or os.getenv('OPENAI_API_KEY', '')
            self.base_url = base_url or 'https://api.siliconflow.cn'
            self.model = model or 'deepseek-ai/DeepSeek-V3'
            self.llm_support_json = llm_support_json or False
        
        if not self.api_key:
            raise GPTError("API key is not set")
    
    def _normalize_base_url(self, base_url: str) -> str:
        """æ ‡å‡†åŒ–åŸºç¡€URL"""
        if 'ark' in base_url:
            return "https://ark.cn-beijing.volces.com/api/v3"
        elif 'v1' not in base_url:
            return base_url.strip('/') + '/v1'
        return base_url
    
    def complete(self, request: GPTRequest) -> GPTResponse:
        """
        æ‰§è¡ŒGPTè¡¥å…¨è¯·æ±‚
        
        Args:
            request: GPTè¯·æ±‚å¯¹è±¡
            
        Returns:
            GPTå“åº”å¯¹è±¡
        """
        # æ£€æŸ¥ç¼“å­˜
        cached_response = self.cache.get(request)
        if cached_response:
            print("ğŸ”„ ä½¿ç”¨ç¼“å­˜å“åº”")
            return cached_response
        
        try:
            # æ„å»ºè¯·æ±‚å‚æ•°
            messages = [{"role": "user", "content": request.prompt}]
            
            # è®¾ç½®å“åº”æ ¼å¼
            response_format = None
            if request.response_type == "json" and self.llm_support_json:
                response_format = {"type": "json_object"}
            
            params = {
                "model": self.model,
                "messages": messages,
                "timeout": request.timeout,
                **request.extra_params
            }
            
            if response_format:
                params["response_format"] = response_format
            
            # å‘é€è¯·æ±‚
            resp_raw = self._client.chat.completions.create(**params)
            
            # å¤„ç†å“åº”
            resp_content = resp_raw.choices[0].message.content
            
            # è§£æJSONå“åº”
            if request.response_type == "json":
                try:
                    parsed_content = json.loads(resp_content)
                except json.JSONDecodeError:
                    # ä½¿ç”¨json_repairä¿®å¤
                    parsed_content = json_repair.loads(resp_content)
            else:
                parsed_content = resp_content
            
            # åˆ›å»ºå“åº”å¯¹è±¡
            response = GPTResponse(
                content=parsed_content,
                raw_content=resp_content,
                request=request,
                model=self.model
            )
            
            # éªŒè¯å“åº”
            if request.validator:
                validation_result = request.validator(parsed_content)
                if validation_result.get('status') != 'success':
                    self.cache.save_error(request, response, validation_result.get('message', 'Validation failed'))
                    raise GPTValidationError(f"Response validation failed: {validation_result.get('message')}")
            
            # ä¿å­˜åˆ°ç¼“å­˜
            self.cache.save(request, response)
            
            return response
            
        except Exception as e:
            if isinstance(e, (GPTError, GPTValidationError)):
                raise
            else:
                raise GPTError(f"GPT request failed: {str(e)}")


def create_gpt_client(config_manager=None, **kwargs) -> GPTClient:
    """
    åˆ›å»ºGPTå®¢æˆ·ç«¯å®ä¾‹
    
    Args:
        config_manager: é…ç½®ç®¡ç†å™¨
        **kwargs: å…¶ä»–åˆå§‹åŒ–å‚æ•°
        
    Returns:
        GPTå®¢æˆ·ç«¯å®ä¾‹
    """
    if config_manager is None:
        try:
            from ..config import get_config_manager
            config_manager = get_config_manager()
        except ImportError:
            print("âš ï¸  é…ç½®ç®¡ç†å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            config_manager = None
    
    return GPTClient(config_manager=config_manager, **kwargs) 