"""
# ----------------------------------------------------------------------------
# GPTç¼“å­˜ç®¡ç†
# 
# è´Ÿè´£GPTè¯·æ±‚å’Œå“åº”çš„ç¼“å­˜ç®¡ç†ï¼Œæé«˜æ•ˆç‡ï¼Œé¿å…é‡å¤è°ƒç”¨
# ----------------------------------------------------------------------------
"""

import os
import json
from pathlib import Path
from threading import Lock
from typing import Optional, Dict, Any

from .models import GPTRequest, GPTResponse


class GPTCache:
    """GPTç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, cache_dir: str = 'output/gpt_log'):
        """
        åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨
        
        Args:
            cache_dir: ç¼“å­˜ç›®å½•
        """
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self._lock = Lock()
        
        print(f"âœ… GPTç¼“å­˜åˆå§‹åŒ–å®Œæˆ: {self.cache_dir}")
    
    def get(self, request: GPTRequest) -> Optional[GPTResponse]:
        """
        è·å–ç¼“å­˜çš„å“åº”
        
        Args:
            request: GPTè¯·æ±‚
            
        Returns:
            ç¼“å­˜çš„å“åº”ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›None
        """
        with self._lock:
            cache_file = self.cache_dir / f"{request.log_title}.json"
            
            if not cache_file.exists():
                return None
            
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    cache_data = json.load(f)
                
                # æŸ¥æ‰¾åŒ¹é…çš„ç¼“å­˜é¡¹
                for item in cache_data:
                    if (item.get("prompt") == request.prompt and 
                        item.get("resp_type") == request.response_type):
                        
                        # é‡å»ºå“åº”å¯¹è±¡
                        response = GPTResponse(
                            content=item.get("resp"),
                            raw_content=item.get("resp_content", ""),
                            request=request,
                            model=item.get("model", "unknown")
                        )
                        return response
                        
            except Exception as e:
                print(f"âš ï¸  è¯»å–ç¼“å­˜å¤±è´¥: {str(e)}")
            
            return None
    
    def save(self, request: GPTRequest, response: GPTResponse) -> None:
        """
        ä¿å­˜å“åº”åˆ°ç¼“å­˜
        
        Args:
            request: GPTè¯·æ±‚
            response: GPTå“åº”
        """
        with self._lock:
            cache_file = self.cache_dir / f"{request.log_title}.json"
            
            # è¯»å–ç°æœ‰ç¼“å­˜
            cache_data = []
            if cache_file.exists():
                try:
                    with open(cache_file, 'r', encoding='utf-8') as f:
                        cache_data = json.load(f)
                except Exception:
                    cache_data = []
            
            # æ·»åŠ æ–°é¡¹
            cache_item = {
                "model": response.model,
                "prompt": request.prompt,
                "resp_content": response.raw_content,
                "resp_type": request.response_type,
                "resp": response.content,
                "message": None
            }
            cache_data.append(cache_item)
            
            # ä¿å­˜ç¼“å­˜
            try:
                with open(cache_file, 'w', encoding='utf-8') as f:
                    json.dump(cache_data, f, ensure_ascii=False, indent=4)
            except Exception as e:
                print(f"âš ï¸  ä¿å­˜ç¼“å­˜å¤±è´¥: {str(e)}")
    
    def save_error(self, request: GPTRequest, response: GPTResponse, error_message: str) -> None:
        """
        ä¿å­˜é”™è¯¯å“åº”åˆ°ç¼“å­˜
        
        Args:
            request: GPTè¯·æ±‚
            response: GPTå“åº”
            error_message: é”™è¯¯æ¶ˆæ¯
        """
        with self._lock:
            error_file = self.cache_dir / "error.json"
            
            # è¯»å–ç°æœ‰é”™è¯¯ç¼“å­˜
            error_data = []
            if error_file.exists():
                try:
                    with open(error_file, 'r', encoding='utf-8') as f:
                        error_data = json.load(f)
                except Exception:
                    error_data = []
            
            # æ·»åŠ é”™è¯¯é¡¹
            error_item = {
                "model": response.model,
                "prompt": request.prompt,
                "resp_content": response.raw_content,
                "resp_type": request.response_type,
                "resp": response.content,
                "message": error_message,
                "log_title": request.log_title
            }
            error_data.append(error_item)
            
            # ä¿å­˜é”™è¯¯ç¼“å­˜
            try:
                with open(error_file, 'w', encoding='utf-8') as f:
                    json.dump(error_data, f, ensure_ascii=False, indent=4)
            except Exception as e:
                print(f"âš ï¸  ä¿å­˜é”™è¯¯ç¼“å­˜å¤±è´¥: {str(e)}")
    
    def clear(self, log_title: Optional[str] = None) -> None:
        """
        æ¸…é™¤ç¼“å­˜
        
        Args:
            log_title: ç‰¹å®šçš„æ—¥å¿—æ ‡é¢˜ï¼Œå¦‚æœä¸ºNoneåˆ™æ¸…é™¤æ‰€æœ‰ç¼“å­˜
        """
        with self._lock:
            if log_title:
                cache_file = self.cache_dir / f"{log_title}.json"
                if cache_file.exists():
                    cache_file.unlink()
                    print(f"ğŸ—‘ï¸  å·²æ¸…é™¤ç¼“å­˜: {log_title}")
            else:
                # æ¸…é™¤æ‰€æœ‰JSONç¼“å­˜æ–‡ä»¶
                for cache_file in self.cache_dir.glob("*.json"):
                    cache_file.unlink()
                print(f"ğŸ—‘ï¸  å·²æ¸…é™¤æ‰€æœ‰ç¼“å­˜")
    
    def get_stats(self) -> Dict[str, Any]:
        """
        è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯
        """
        stats = {
            'total_files': 0,
            'total_entries': 0,
            'cache_size_mb': 0.0,
            'log_titles': []
        }
        
        try:
            cache_files = list(self.cache_dir.glob("*.json"))
            stats['total_files'] = len(cache_files)
            
            total_size = 0
            for cache_file in cache_files:
                total_size += cache_file.stat().st_size
                
                if cache_file.name != 'error.json':
                    stats['log_titles'].append(cache_file.stem)
                    
                    try:
                        with open(cache_file, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                            stats['total_entries'] += len(data)
                    except Exception:
                        pass
            
            stats['cache_size_mb'] = round(total_size / (1024 * 1024), 2)
            
        except Exception as e:
            print(f"âš ï¸  è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {str(e)}")
        
        return stats 