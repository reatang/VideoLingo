"""
# ----------------------------------------------------------------------------
# å­—å¹•ç”Ÿæˆå™¨æ¨¡å— - å¤šæ ¼å¼å­—å¹•æ–‡ä»¶ç”Ÿæˆå’Œæ—¶é—´è½´å¯¹é½
# 
# æ ¸å¿ƒåŠŸèƒ½ï¼š
# 1. æ™ºèƒ½å­—å¹•é•¿åº¦åˆ†å‰²å’Œå†…å®¹ä¼˜åŒ–
# 2. ç²¾å‡†æ—¶é—´è½´å¯¹é½å’Œé—´éš”ä¼˜åŒ–
# 3. å¤šæ ¼å¼å­—å¹•æ–‡ä»¶ç”Ÿæˆ (SRT, VTT, ASSç­‰)
# 4. åŒè¯­å­—å¹•å’Œæ ·å¼è‡ªå®šä¹‰
# 5. éŸ³é¢‘é…éŸ³ç”¨å­—å¹•ä¸“é—¨å¤„ç†
# 6. å­—å¹•è´¨é‡æ£€æµ‹å’Œä¿®å¤
# 
# è¾“å…¥ï¼šç¿»è¯‘ç»“æœExcelï¼Œè½¬å½•éŸ³é¢‘æ•°æ®
# è¾“å‡ºï¼šå¤šç§æ ¼å¼çš„å­—å¹•æ–‡ä»¶
# 
# è®¾è®¡åŸåˆ™ï¼š
# - ç¡®ä¿å­—å¹•æ—¶é—´è½´çš„ç²¾ç¡®å¯¹é½
# - æ”¯æŒå¤šç§å­—å¹•æ ¼å¼å’Œæ ·å¼é…ç½®
# - æ™ºèƒ½å¤„ç†å­—å¹•é•¿åº¦å’Œæ˜¾ç¤ºæ•ˆæœ
# - ä¸ºéŸ³é¢‘é…éŸ³æä¾›ä¸“é—¨çš„å­—å¹•æ”¯æŒ
# ----------------------------------------------------------------------------
"""

import os
import re
import json
import math
from typing import List, Dict, Optional, Tuple, Any, Union
from pathlib import Path
import concurrent.futures
from dataclasses import dataclass, asdict
from collections import defaultdict
from datetime import datetime, timedelta
import warnings

warnings.filterwarnings("ignore", category=FutureWarning)


@dataclass
class SubtitleSegment:
    """å­—å¹•ç‰‡æ®µæ•°æ®ç±»"""
    index: int                      # ç‰‡æ®µç´¢å¼•
    start_time: float              # å¼€å§‹æ—¶é—´ï¼ˆç§’ï¼‰
    end_time: float                # ç»“æŸæ—¶é—´ï¼ˆç§’ï¼‰
    duration: float                # æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
    source_text: str               # æºè¯­è¨€æ–‡æœ¬
    translated_text: str = ""      # ç¿»è¯‘æ–‡æœ¬
    display_source: str = ""       # æ˜¾ç¤ºç”¨æºæ–‡æœ¬
    display_translation: str = ""  # æ˜¾ç¤ºç”¨ç¿»è¯‘æ–‡æœ¬
    confidence: float = 1.0        # å¯¹é½ç½®ä¿¡åº¦
    needs_split: bool = False      # æ˜¯å¦éœ€è¦åˆ†å‰²
    
    def get_srt_timestamp(self) -> str:
        """è·å–SRTæ ¼å¼çš„æ—¶é—´æˆ³"""
        return self._seconds_to_srt_format(self.start_time, self.end_time)
    
    def _seconds_to_srt_format(self, start: float, end: float) -> str:
        """å°†ç§’æ•°è½¬æ¢ä¸ºSRTæ—¶é—´æ ¼å¼"""
        def seconds_to_hmsm(seconds: float) -> str:
            hours = int(seconds // 3600)
            minutes = int((seconds % 3600) // 60)
            secs = seconds % 60
            milliseconds = int(secs * 1000) % 1000
            return f"{hours:02d}:{minutes:02d}:{int(secs):02d},{milliseconds:03d}"
        
        start_srt = seconds_to_hmsm(start)
        end_srt = seconds_to_hmsm(end)
        return f"{start_srt} --> {end_srt}"


@dataclass
class SubtitleConfig:
    """å­—å¹•é…ç½®æ•°æ®ç±»"""
    max_length: int = 50           # æœ€å¤§å­—ç¬¦é•¿åº¦
    target_multiplier: float = 2.5 # ç›®æ ‡è¯­è¨€é•¿åº¦å€æ•°
    min_duration: float = 1.0      # æœ€å°æ˜¾ç¤ºæ—¶é•¿
    max_duration: float = 6.0      # æœ€å¤§æ˜¾ç¤ºæ—¶é•¿
    gap_threshold: float = 1.0     # é—´éš”é˜ˆå€¼
    font_size: int = 16           # å­—ä½“å¤§å°
    font_name: str = "Arial"      # å­—ä½“åç§°
    enable_dual_language: bool = True # æ˜¯å¦å¯ç”¨åŒè¯­


@dataclass
class SubtitleGenerationResult:
    """å­—å¹•ç”Ÿæˆç»“æœæ•°æ®ç±»"""
    total_segments: int            # æ€»ç‰‡æ®µæ•°
    generated_files: List[str]     # ç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨
    processing_time: float         # å¤„ç†æ—¶é—´
    average_duration: float        # å¹³å‡æ—¶é•¿
    split_segments: int = 0        # æ‹†åˆ†çš„ç‰‡æ®µæ•°
    alignment_issues: int = 0      # å¯¹é½é—®é¢˜æ•°
    
    def __post_init__(self):
        if not self.generated_files:
            self.generated_files = []


class SubtitleGenerator:
    """å­—å¹•ç”Ÿæˆå™¨ç±» - å¤šæ ¼å¼å­—å¹•æ–‡ä»¶ç”Ÿæˆ"""
    
    def __init__(self,
                 translation_file: str = 'output/log/4_2_translation.xlsx',
                 audio_data_file: str = 'output/log/2_cleaned_chunks.xlsx',
                 output_dir: str = 'output',
                 audio_output_dir: str = 'output/audio',
                 src_language: str = 'en',
                 tgt_language: str = 'zh',
                 subtitle_config: Optional[SubtitleConfig] = None,
                 max_workers: int = 4):
        """
        åˆå§‹åŒ–å­—å¹•ç”Ÿæˆå™¨
        
        Args:
            translation_file: ç¿»è¯‘ç»“æœæ–‡ä»¶
            audio_data_file: éŸ³é¢‘æ•°æ®æ–‡ä»¶ï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰
            output_dir: å­—å¹•è¾“å‡ºç›®å½•
            audio_output_dir: éŸ³é¢‘ç”¨å­—å¹•è¾“å‡ºç›®å½•
            src_language: æºè¯­è¨€ä»£ç 
            tgt_language: ç›®æ ‡è¯­è¨€ä»£ç 
            subtitle_config: å­—å¹•é…ç½®å¯¹è±¡
            max_workers: å¹¶è¡Œå¤„ç†çš„æœ€å¤§çº¿ç¨‹æ•°
        """
        self.translation_file = Path(translation_file)
        self.audio_data_file = Path(audio_data_file)
        self.output_dir = Path(output_dir)
        self.audio_output_dir = Path(audio_output_dir)
        self.src_language = src_language
        self.tgt_language = tgt_language
        self.subtitle_config = subtitle_config or SubtitleConfig()
        self.max_workers = max_workers
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.audio_output_dir.mkdir(parents=True, exist_ok=True)
        
        # å­—å¹•è¾“å‡ºé…ç½®
        self.subtitle_output_configs = [
            ('src.srt', ['source']),
            ('trans.srt', ['translation']),
            ('src_trans.srt', ['source', 'translation']),
            ('trans_src.srt', ['translation', 'source'])
        ]
        
        self.audio_subtitle_configs = [
            ('src_subs_for_audio.srt', ['source']),
            ('trans_subs_for_audio.srt', ['translation'])
        ]
        
        # æ‡’åŠ è½½ä¾èµ–
        self._pd = None
        self._ask_gpt_func = None
        
        # å†…éƒ¨çŠ¶æ€
        self._audio_words_data = []
        self._translation_data = []
        self._segments = []
        
    def _get_pandas(self):
        """æ‡’åŠ è½½pandas"""
        if self._pd is None:
            try:
                import pandas as pd
                self._pd = pd
            except ImportError:
                raise ImportError("âŒ æœªæ‰¾åˆ°pandasåº“, è¯·å®‰è£…: pip install pandas")
        return self._pd
    
    def set_gpt_function(self, ask_gpt_func):
        """
        è®¾ç½®GPTè°ƒç”¨å‡½æ•°ï¼ˆç”¨äºå­—å¹•åˆ†å‰²ä¼˜åŒ–ï¼‰
        
        Args:
            ask_gpt_func: GPT APIè°ƒç”¨å‡½æ•°
        """
        self._ask_gpt_func = ask_gpt_func
        print("âœ… GPTå‡½æ•°å·²è®¾ç½®ï¼ˆç”¨äºå­—å¹•åˆ†å‰²ä¼˜åŒ–ï¼‰")
    
    def load_audio_data(self) -> List[Dict]:
        """
        åŠ è½½éŸ³é¢‘è¯çº§æ•°æ®
        
        Returns:
            è¯çº§æ•°æ®åˆ—è¡¨
        """
        print(f"ğŸ“– æ­£åœ¨åŠ è½½éŸ³é¢‘æ•°æ®: {self.audio_data_file}")
        
        if not self.audio_data_file.exists():
            raise FileNotFoundError(f"âŒ éŸ³é¢‘æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {self.audio_data_file}")
        
        try:
            pd = self._get_pandas()
            df = pd.read_excel(self.audio_data_file)
            
            # æ£€æŸ¥å¿…éœ€çš„åˆ—
            required_columns = ['text', 'start', 'end']
            if not all(col in df.columns for col in required_columns):
                raise ValueError(f"âŒ éŸ³é¢‘æ•°æ®æ–‡ä»¶ç¼ºå°‘å¿…éœ€åˆ—: {required_columns}")
            
            # è½¬æ¢ä¸ºè¯çº§æ•°æ®
            words_data = []
            for _, row in df.iterrows():
                if pd.notna(row['text']) and pd.notna(row['start']) and pd.notna(row['end']):
                    words_data.append({
                        'text': str(row['text']).strip().strip('"'),
                        'start': float(row['start']),
                        'end': float(row['end'])
                    })
            
            print(f"âœ… åŠ è½½äº†{len(words_data)}ä¸ªéŸ³é¢‘ç‰‡æ®µ")
            return words_data
            
        except Exception as e:
            print(f"âŒ åŠ è½½éŸ³é¢‘æ•°æ®å¤±è´¥: {str(e)}")
            raise
    
    def load_translation_data(self) -> List[Dict]:
        """
        åŠ è½½ç¿»è¯‘æ•°æ®
        
        Returns:
            ç¿»è¯‘æ•°æ®åˆ—è¡¨
        """
        print(f"ğŸ“– æ­£åœ¨åŠ è½½ç¿»è¯‘æ•°æ®: {self.translation_file}")
        
        if not self.translation_file.exists():
            raise FileNotFoundError(f"âŒ ç¿»è¯‘æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {self.translation_file}")
        
        try:
            pd = self._get_pandas()
            df = pd.read_excel(self.translation_file)
            
            # æ£€æŸ¥å¿…éœ€çš„åˆ—
            required_columns = ['Source', 'Translation']
            if not all(col in df.columns for col in required_columns):
                raise ValueError(f"âŒ ç¿»è¯‘æ•°æ®æ–‡ä»¶ç¼ºå°‘å¿…éœ€åˆ—: {required_columns}")
            
            # è½¬æ¢ä¸ºç¿»è¯‘æ•°æ®
            translation_data = []
            for _, row in df.iterrows():
                if pd.notna(row['Source']):
                    translation_data.append({
                        'source': str(row['Source']).strip(),
                        'translation': str(row['Translation']).strip() if pd.notna(row['Translation']) else ""
                    })
            
            print(f"âœ… åŠ è½½äº†{len(translation_data)}ä¸ªç¿»è¯‘æ¡ç›®")
            return translation_data
            
        except Exception as e:
            print(f"âŒ åŠ è½½ç¿»è¯‘æ•°æ®å¤±è´¥: {str(e)}")
            raise
    
    def calculate_text_weight(self, text: str) -> float:
        """
        è®¡ç®—æ–‡æœ¬æ˜¾ç¤ºæƒé‡ï¼ˆè€ƒè™‘ä¸åŒè¯­è¨€å­—ç¬¦çš„æ˜¾ç¤ºå®½åº¦ï¼‰
        
        Args:
            text: æ–‡æœ¬å†…å®¹
            
        Returns:
            æ–‡æœ¬æ˜¾ç¤ºæƒé‡
        """
        if not text:
            return 0.0
        
        weight = 0.0
        for char in str(text):
            code = ord(char)
            if 0x4E00 <= code <= 0x9FFF or 0x3040 <= code <= 0x30FF:  # ä¸­æ–‡å’Œæ—¥æ–‡
                weight += 1.75
            elif 0xAC00 <= code <= 0xD7A3 or 0x1100 <= code <= 0x11FF:  # éŸ©æ–‡
                weight += 1.5
            elif 0x0E00 <= code <= 0x0E7F:  # æ³°æ–‡
                weight += 1.0
            elif 0xFF01 <= code <= 0xFF5E:  # å…¨è§’ç¬¦å·
                weight += 1.75
            else:  # å…¶ä»–å­—ç¬¦ï¼ˆè‹±æ–‡ã€åŠè§’ç¬¦å·ç­‰ï¼‰
                weight += 1.0
        
        return weight
    
    def clean_text_for_matching(self, text: str) -> str:
        """
        æ¸…ç†æ–‡æœ¬ç”¨äºåŒ¹é…ï¼ˆç§»é™¤æ ‡ç‚¹å’Œç©ºæ ¼ï¼‰
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            æ¸…ç†åçš„æ–‡æœ¬
        """
        if not text:
            return ""
        
        # ç§»é™¤å¤šä½™ç©ºæ ¼
        text = re.sub(r'\s+', ' ', text)
        # ç§»é™¤æ ‡ç‚¹ç¬¦å·
        text = re.sub(r'[^\w\s]', '', text)
        return text.strip().lower()
    
    def align_timestamps(self, audio_words: List[Dict], translations: List[Dict]) -> List[SubtitleSegment]:
        """
        å¯¹é½æ—¶é—´æˆ³ï¼Œå°†ç¿»è¯‘æ–‡æœ¬åŒ¹é…åˆ°éŸ³é¢‘æ—¶é—´æˆ³
        
        Args:
            audio_words: éŸ³é¢‘è¯çº§æ•°æ®
            translations: ç¿»è¯‘æ•°æ®
            
        Returns:
            å¯¹é½åçš„å­—å¹•ç‰‡æ®µåˆ—è¡¨
        """
        print("â° æ­£åœ¨è¿›è¡Œæ—¶é—´æˆ³å¯¹é½...")
        
        segments = []
        
        # æ„å»ºå®Œæ•´çš„éŸ³é¢‘æ–‡æœ¬å­—ç¬¦ä¸²å’Œä½ç½®æ˜ å°„
        full_audio_text = ''
        position_to_word_idx = {}
        
        for idx, word_data in enumerate(audio_words):
            clean_word = self.clean_text_for_matching(word_data['text'])
            start_pos = len(full_audio_text)
            full_audio_text += clean_word
            
            # å»ºç«‹ä½ç½®åˆ°è¯ç´¢å¼•çš„æ˜ å°„
            for pos in range(start_pos, len(full_audio_text)):
                position_to_word_idx[pos] = idx
        
        print(f"ğŸ“ æ„å»ºäº†{len(full_audio_text)}å­—ç¬¦çš„éŸ³é¢‘æ–‡æœ¬ç´¢å¼•")
        
        # å¯¹æ¯ä¸ªç¿»è¯‘å¥å­è¿›è¡Œæ—¶é—´æˆ³åŒ¹é…
        current_pos = 0
        
        for idx, trans_data in enumerate(translations):
            source_text = trans_data['source']
            translation_text = trans_data['translation']
            
            clean_sentence = self.clean_text_for_matching(source_text).replace(" ", "")
            sentence_len = len(clean_sentence)
            
            if sentence_len == 0:
                print(f"âš ï¸  è·³è¿‡ç©ºå¥å­: {idx}")
                continue
            
            # åœ¨éŸ³é¢‘æ–‡æœ¬ä¸­æŸ¥æ‰¾åŒ¹é…
            match_found = False
            search_start = current_pos
            
            while search_start <= len(full_audio_text) - sentence_len:
                if full_audio_text[search_start:search_start + sentence_len] == clean_sentence:
                    # æ‰¾åˆ°åŒ¹é…ï¼Œè·å–å¯¹åº”çš„è¯ç´¢å¼•
                    start_word_idx = position_to_word_idx[search_start]
                    end_word_idx = position_to_word_idx[search_start + sentence_len - 1]
                    
                    # è·å–æ—¶é—´æˆ³
                    start_time = float(audio_words[start_word_idx]['start'])
                    end_time = float(audio_words[end_word_idx]['end'])
                    duration = end_time - start_time
                    
                    # åˆ›å»ºå­—å¹•ç‰‡æ®µ
                    segment = SubtitleSegment(
                        index=len(segments),
                        start_time=start_time,
                        end_time=end_time,
                        duration=duration,
                        source_text=source_text,
                        translated_text=translation_text,
                        confidence=1.0
                    )
                    
                    segments.append(segment)
                    current_pos = search_start + sentence_len
                    match_found = True
                    break
                
                search_start += 1
            
            if not match_found:
                print(f"âš ï¸  æœªæ‰¾åˆ°åŒ¹é…çš„æ—¶é—´æˆ³: {source_text[:50]}...")
                # åˆ›å»ºä¸€ä¸ªå ä½ç¬¦ç‰‡æ®µ
                prev_end = segments[-1].end_time if segments else 0.0
                segment = SubtitleSegment(
                    index=len(segments),
                    start_time=prev_end,
                    end_time=prev_end + 2.0,  # é»˜è®¤2ç§’æ—¶é•¿
                    duration=2.0,
                    source_text=source_text,
                    translated_text=translation_text,
                    confidence=0.5
                )
                segments.append(segment)
        
        print(f"âœ… å®Œæˆæ—¶é—´æˆ³å¯¹é½ï¼Œç”Ÿæˆ{len(segments)}ä¸ªå­—å¹•ç‰‡æ®µ")
        return segments
    
    def optimize_subtitle_gaps(self, segments: List[SubtitleSegment]) -> List[SubtitleSegment]:
        """
        ä¼˜åŒ–å­—å¹•é—´éš”ï¼Œæ¶ˆé™¤å°é—´éš™
        
        Args:
            segments: åŸå§‹å­—å¹•ç‰‡æ®µ
            
        Returns:
            ä¼˜åŒ–åçš„å­—å¹•ç‰‡æ®µ
        """
        print("ğŸ•³ï¸  æ­£åœ¨ä¼˜åŒ–å­—å¹•é—´éš”...")
        
        if not segments:
            return segments
        
        optimized_segments = []
        
        for i, segment in enumerate(segments):
            new_segment = SubtitleSegment(**asdict(segment))
            
            # æ£€æŸ¥ä¸ä¸‹ä¸€ä¸ªç‰‡æ®µçš„é—´éš”
            if i < len(segments) - 1:
                next_segment = segments[i + 1]
                gap = next_segment.start_time - segment.end_time
                
                # å¦‚æœé—´éš”å°äºé˜ˆå€¼ï¼Œå»¶é•¿å½“å‰ç‰‡æ®µ
                if 0 < gap < self.subtitle_config.gap_threshold:
                    new_segment.end_time = next_segment.start_time
                    new_segment.duration = new_segment.end_time - new_segment.start_time
                    print(f"ğŸ”§ ä¼˜åŒ–ç‰‡æ®µ{i}ï¼šæ¶ˆé™¤{gap:.2f}ç§’é—´éš”")
            
            optimized_segments.append(new_segment)
        
        print(f"âœ… é—´éš”ä¼˜åŒ–å®Œæˆ")
        return optimized_segments
    
    def check_subtitle_length(self, segments: List[SubtitleSegment]) -> List[SubtitleSegment]:
        """
        æ£€æŸ¥å¹¶æ ‡è®°éœ€è¦åˆ†å‰²çš„å­—å¹•
        
        Args:
            segments: å­—å¹•ç‰‡æ®µåˆ—è¡¨
            
        Returns:
            æ£€æŸ¥åçš„å­—å¹•ç‰‡æ®µ
        """
        print("ğŸ“ æ­£åœ¨æ£€æŸ¥å­—å¹•é•¿åº¦...")
        
        needs_split_count = 0
        
        for segment in segments:
            source_len = len(segment.source_text)
            trans_weight = self.calculate_text_weight(segment.translated_text)
            trans_display_len = trans_weight * self.subtitle_config.target_multiplier
            
            if (source_len > self.subtitle_config.max_length or 
                trans_display_len > self.subtitle_config.max_length):
                segment.needs_split = True
                needs_split_count += 1
                print(f"ğŸ“ ç‰‡æ®µ{segment.index}éœ€è¦åˆ†å‰²: æºæ–‡æœ¬{source_len}å­—ç¬¦, ç¿»è¯‘{trans_weight:.1f}æƒé‡")
        
        print(f"âœ… é•¿åº¦æ£€æŸ¥å®Œæˆï¼Œ{needs_split_count}ä¸ªç‰‡æ®µéœ€è¦åˆ†å‰²")
        return segments
    
    def split_long_subtitles(self, segments: List[SubtitleSegment]) -> List[SubtitleSegment]:
        """
        åˆ†å‰²è¿‡é•¿çš„å­—å¹•
        
        Args:
            segments: å­—å¹•ç‰‡æ®µåˆ—è¡¨
            
        Returns:
            åˆ†å‰²åçš„å­—å¹•ç‰‡æ®µ
        """
        print("âœ‚ï¸  æ­£åœ¨åˆ†å‰²è¿‡é•¿å­—å¹•...")
        
        result_segments = []
        split_count = 0
        
        for segment in segments:
            if not segment.needs_split:
                result_segments.append(segment)
                continue
            
            # ç®€å•åˆ†å‰²ï¼šæŒ‰é•¿åº¦ä¸€åˆ†ä¸ºäºŒ
            source_text = segment.source_text
            translated_text = segment.translated_text
            
            mid_point_source = len(source_text) // 2
            mid_point_trans = len(translated_text) // 2
            
            # æ‰¾åˆ°è¾ƒå¥½çš„åˆ†å‰²ç‚¹ï¼ˆç©ºæ ¼æˆ–æ ‡ç‚¹ï¼‰
            source_split_point = self._find_best_split_point(source_text, mid_point_source)
            trans_split_point = self._find_best_split_point(translated_text, mid_point_trans)
            
            # æ—¶é—´åˆ†å‰²
            duration_each = segment.duration / 2
            
            # åˆ›å»ºä¸¤ä¸ªæ–°ç‰‡æ®µ
            segment1 = SubtitleSegment(
                index=len(result_segments),
                start_time=segment.start_time,
                end_time=segment.start_time + duration_each,
                duration=duration_each,
                source_text=source_text[:source_split_point].strip(),
                translated_text=translated_text[:trans_split_point].strip(),
                confidence=segment.confidence * 0.8  # åˆ†å‰²ä¼šé™ä½ç½®ä¿¡åº¦
            )
            
            segment2 = SubtitleSegment(
                index=len(result_segments) + 1,
                start_time=segment.start_time + duration_each,
                end_time=segment.end_time,
                duration=duration_each,
                source_text=source_text[source_split_point:].strip(),
                translated_text=translated_text[trans_split_point:].strip(),
                confidence=segment.confidence * 0.8
            )
            
            result_segments.extend([segment1, segment2])
            split_count += 1
        
        print(f"âœ… å­—å¹•åˆ†å‰²å®Œæˆï¼Œåˆ†å‰²äº†{split_count}ä¸ªç‰‡æ®µ")
        return result_segments
    
    def _find_best_split_point(self, text: str, mid_point: int) -> int:
        """
        åœ¨æ–‡æœ¬ä¸­æ‰¾åˆ°æœ€ä½³åˆ†å‰²ç‚¹
        
        Args:
            text: è¦åˆ†å‰²çš„æ–‡æœ¬
            mid_point: ä¸­ç‚¹ä½ç½®
            
        Returns:
            æœ€ä½³åˆ†å‰²ç‚¹ä½ç½®
        """
        if not text or mid_point <= 0 or mid_point >= len(text):
            return mid_point
        
        # åœ¨ä¸­ç‚¹é™„è¿‘å¯»æ‰¾ç©ºæ ¼æˆ–æ ‡ç‚¹
        search_range = min(20, len(text) // 4)
        
        # å‘åæœç´¢
        for i in range(mid_point, min(mid_point + search_range, len(text))):
            if text[i] in ' ,.!?;ã€‚ï¼Œï¼ï¼Ÿï¼›':
                return i + 1
        
        # å‘å‰æœç´¢
        for i in range(mid_point, max(mid_point - search_range, 0), -1):
            if text[i] in ' ,.!?;ã€‚ï¼Œï¼ï¼Ÿï¼›':
                return i + 1
        
        # å¦‚æœæ²¡æ‰¾åˆ°åˆé€‚çš„åˆ†å‰²ç‚¹ï¼Œä½¿ç”¨ä¸­ç‚¹
        return mid_point
    
    def prepare_display_text(self, segments: List[SubtitleSegment]) -> List[SubtitleSegment]:
        """
        å‡†å¤‡æ˜¾ç¤ºç”¨æ–‡æœ¬ï¼ˆæ¸…ç†å’Œç¾åŒ–ï¼‰
        
        Args:
            segments: å­—å¹•ç‰‡æ®µåˆ—è¡¨
            
        Returns:
            å‡†å¤‡å¥½æ˜¾ç¤ºæ–‡æœ¬çš„å­—å¹•ç‰‡æ®µ
        """
        print("âœ¨ æ­£åœ¨å‡†å¤‡æ˜¾ç¤ºæ–‡æœ¬...")
        
        for segment in segments:
            # æ¸…ç†æºæ–‡æœ¬
            segment.display_source = self._clean_display_text(segment.source_text)
            
            # æ¸…ç†ç¿»è¯‘æ–‡æœ¬
            segment.display_translation = self._clean_display_text(segment.translated_text)
        
        print("âœ… æ˜¾ç¤ºæ–‡æœ¬å‡†å¤‡å®Œæˆ")
        return segments
    
    def _clean_display_text(self, text: str) -> str:
        """
        æ¸…ç†æ˜¾ç¤ºæ–‡æœ¬
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            
        Returns:
            æ¸…ç†åçš„æ–‡æœ¬
        """
        if not text:
            return ""
        
        # ç§»é™¤å¤šä½™çš„æ ‡ç‚¹ç¬¦å·
        text = re.sub(r'[ï¼Œã€‚]', ' ', text)
        # æ¸…ç†å¤šä½™ç©ºæ ¼
        text = re.sub(r'\s+', ' ', text)
        return text.strip()
    
    def generate_srt_content(self, segments: List[SubtitleSegment], columns: List[str]) -> str:
        """
        ç”ŸæˆSRTæ ¼å¼å†…å®¹
        
        Args:
            segments: å­—å¹•ç‰‡æ®µåˆ—è¡¨
            columns: è¦åŒ…å«çš„åˆ— ['source', 'translation']
            
        Returns:
            SRTæ ¼å¼å­—ç¬¦ä¸²
        """
        srt_content = []
        
        for i, segment in enumerate(segments, 1):
            srt_content.append(f"{i}")
            srt_content.append(segment.get_srt_timestamp())
            
            # æ ¹æ®é…ç½®æ·»åŠ æ–‡æœ¬è¡Œ
            for column in columns:
                if column == 'source' and segment.display_source:
                    srt_content.append(segment.display_source)
                elif column == 'translation' and segment.display_translation:
                    srt_content.append(segment.display_translation)
            
            srt_content.append("")  # ç©ºè¡Œåˆ†éš”
        
        return '\n'.join(srt_content).strip()
    
    def save_subtitle_files(self, segments: List[SubtitleSegment], for_audio: bool = False) -> List[str]:
        """
        ä¿å­˜å­—å¹•æ–‡ä»¶
        
        Args:
            segments: å­—å¹•ç‰‡æ®µåˆ—è¡¨
            for_audio: æ˜¯å¦ä¸ºéŸ³é¢‘é…éŸ³ç”¨å­—å¹•
            
        Returns:
            ç”Ÿæˆçš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜{'éŸ³é¢‘ç”¨' if for_audio else 'æ˜¾ç¤ºç”¨'}å­—å¹•æ–‡ä»¶...")
        
        output_dir = self.audio_output_dir if for_audio else self.output_dir
        configs = self.audio_subtitle_configs if for_audio else self.subtitle_output_configs
        
        generated_files = []
        
        for filename, columns in configs:
            file_path = output_dir / filename
            srt_content = self.generate_srt_content(segments, columns)
            
            try:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(srt_content)
                
                generated_files.append(str(file_path))
                print(f"âœ… ç”Ÿæˆ: {file_path}")
                
            except Exception as e:
                print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥ {file_path}: {str(e)}")
        
        return generated_files
    
    def process_complete_subtitle_generation(self) -> SubtitleGenerationResult:
        """
        å®Œæ•´çš„å­—å¹•ç”Ÿæˆå¤„ç†æµç¨‹
        
        Returns:
            å­—å¹•ç”Ÿæˆç»“æœ
        """
        print("ğŸš€ å¼€å§‹å®Œæ•´å­—å¹•ç”Ÿæˆæµç¨‹...")
        
        import time
        start_time = time.time()
        
        try:
            # 1. åŠ è½½æ•°æ®
            audio_words = self.load_audio_data()
            translations = self.load_translation_data()
            
            # 2. æ—¶é—´æˆ³å¯¹é½
            segments = self.align_timestamps(audio_words, translations)
            
            # 3. ä¼˜åŒ–é—´éš”
            segments = self.optimize_subtitle_gaps(segments)
            
            # 4. æ£€æŸ¥é•¿åº¦
            segments = self.check_subtitle_length(segments)
            
            # 5. åˆ†å‰²è¿‡é•¿å­—å¹•
            original_count = len(segments)
            segments = self.split_long_subtitles(segments)
            split_count = len(segments) - original_count
            
            # 6. å‡†å¤‡æ˜¾ç¤ºæ–‡æœ¬
            segments = self.prepare_display_text(segments)
            
            # 7. ä¿å­˜å­—å¹•æ–‡ä»¶
            display_files = self.save_subtitle_files(segments, for_audio=False)
            audio_files = self.save_subtitle_files(segments, for_audio=True)
            
            processing_time = time.time() - start_time
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            total_duration = sum(seg.duration for seg in segments)
            average_duration = total_duration / len(segments) if segments else 0
            alignment_issues = sum(1 for seg in segments if seg.confidence < 1.0)
            
            result = SubtitleGenerationResult(
                total_segments=len(segments),
                generated_files=display_files + audio_files,
                processing_time=processing_time,
                average_duration=average_duration,
                split_segments=split_count,
                alignment_issues=alignment_issues
            )
            
            print("ğŸ‰ å­—å¹•ç”Ÿæˆæµç¨‹å®Œæˆï¼")
            print(f"ğŸ“Š ç”Ÿæˆç»Ÿè®¡:")
            print(f"  ğŸ“„ æ€»ç‰‡æ®µæ•°: {result.total_segments}")
            print(f"  âœ‚ï¸  åˆ†å‰²ç‰‡æ®µ: {result.split_segments}")
            print(f"  âš ï¸  å¯¹é½é—®é¢˜: {result.alignment_issues}")
            print(f"  â±ï¸  å¹³å‡æ—¶é•¿: {result.average_duration:.2f}ç§’")
            print(f"  ğŸ•’ å¤„ç†è€—æ—¶: {result.processing_time:.2f}ç§’")
            print(f"  ğŸ“ ç”Ÿæˆæ–‡ä»¶: {len(result.generated_files)}ä¸ª")
            
            return result
            
        except Exception as e:
            print(f"ğŸ’¥ å­—å¹•ç”Ÿæˆæµç¨‹å¤±è´¥: {str(e)}")
            raise


# ----------------------------------------------------------------------------
# ç‹¬ç«‹è¿è¡Œæµ‹è¯•
# ----------------------------------------------------------------------------
if __name__ == '__main__':
    import sys
    
    # åˆ›å»ºå­—å¹•ç”Ÿæˆå™¨å®ä¾‹
    generator = SubtitleGenerator(
        src_language='en',
        tgt_language='zh',
        subtitle_config=SubtitleConfig(
            max_length=50,
            target_multiplier=2.5,
            min_duration=1.0,
            max_duration=6.0
        )
    )
    
    try:
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
        if not generator.translation_file.exists():
            print(f"âŒ ç¿»è¯‘æ–‡ä»¶ä¸å­˜åœ¨: {generator.translation_file}")
            print("ğŸ’¡ è¯·å…ˆè¿è¡Œæ–‡æœ¬ç¿»è¯‘å™¨ç”Ÿæˆç¿»è¯‘æ–‡ä»¶")
            sys.exit(1)
        
        if not generator.audio_data_file.exists():
            print(f"âŒ éŸ³é¢‘æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {generator.audio_data_file}")
            print("ğŸ’¡ è¯·å…ˆè¿è¡ŒéŸ³é¢‘è½¬å½•å™¨ç”ŸæˆéŸ³é¢‘æ•°æ®æ–‡ä»¶")
            sys.exit(1)
        
        # è¿è¡Œå®Œæ•´å­—å¹•ç”Ÿæˆæµç¨‹
        print("\nğŸ§ª æµ‹è¯•å­—å¹•ç”Ÿæˆæµç¨‹...")
        
        result = generator.process_complete_subtitle_generation()
        
        print(f"\nâœ… æµ‹è¯•å®Œæˆï¼")
        print(f"ğŸ“ ç”Ÿæˆçš„å­—å¹•æ–‡ä»¶:")
        for i, file_path in enumerate(result.generated_files, 1):
            print(f"  {i}. {file_path}")
        
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        sys.exit(1) 